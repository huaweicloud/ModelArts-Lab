{"cells": [{"metadata": {}, "cell_type": "markdown", "source": "# \u4f7f\u7528MoXing\u5b9e\u73b0\u624b\u5199\u6570\u5b57\u56fe\u50cf\u8bc6\u522b\u5e94\u7528\n\n  &#160;&#160;\u672c\u5185\u5bb9\u4e3b\u8981\u4ecb\u7ecd\uff0c\u5982\u4f55\u4f7f\u7528MoXing\u5b9e\u73b0\u624b\u5199\u6570\u5b57\u56fe\u50cf\u7684\u8bad\u7ec3\u3001\u6d4b\u8bd5\u5e94\u7528\u3002  \n  \n### [1. \u51c6\u5907\u6570\u636e](#data_prepare)\n### [2. \u8bad\u7ec3\u6a21\u578b](#train)\n### [3. \u9884\u6d4b](#predict)"}, {"metadata": {}, "cell_type": "markdown", "source": "\n\n## <a name=\"data_prepare\">1. \u51c6\u5907\u6570\u636e</a>  \n  &#160;&#160;\u4eceobs\u7684mnist\u6876\u7684mnist_data\u5bf9\u8c61\u4e2d\u4e0b\u8f7dMNIST\u6570\u636e\u96c6\uff0c\u5e76\u4e0a\u4f20\u81f3\u79c1\u6709\u7684OBS\u6876\u4e2d\u3002\n  \n1.1 &#160; &#160; \u4e0b\u8f7dMNIST\u6570\u636e\u96c6\uff0c \u6570\u636e\u96c6\u6587\u4ef6\u8bf4\u660e\u5982\u4e0b\uff1a\n- t10k-images-idx3-ubyte.gz\uff1a\u9a8c\u8bc1\u96c6\uff0c\u5171\u5305\u542b10000\u4e2a\u6837\u672c\u3002\n- t10k-labels-idx1-ubyte.gz\uff1a\u9a8c\u8bc1\u96c6\u6807\u7b7e\uff0c\u5171\u5305\u542b10000\u4e2a\u6837\u672c\u7684\u7c7b\u522b\u6807\u7b7e\u3002\n- train-images-idx3-ubyte.gz\uff1a\u8bad\u7ec3\u96c6\uff0c\u5171\u5305\u542b60000\u4e2a\u6837\u672c\u3002\n- train-labels-idx1-ubyte.gz\uff1a\u8bad\u7ec3\u96c6\u6807\u7b7e\uff0c\u5171\u5305\u542b60000\u4e2a\u6837\u672c\u7684\u7c7b\u522b\u6807\u7b7e\u3002\n\n1.2 &#160; &#160; .gz\u6570\u636e\u65e0\u9700\u89e3\u538b\uff0c\u5206\u522b\u4e0a\u4f20\u81f3\u534e\u4e3a\u4e91OBS\u6876 ,\u8be5\u6570\u636e\u8def\u5f84\u5c06\u8bbe\u7f6e\u4e3adata_url\u3002"}, {"metadata": {}, "cell_type": "markdown", "source": "# <a name=\"train\">2. \u8bad\u7ec3\u6a21\u578b</a>  \n\n  &#160;&#160;\u901a\u8fc7import\u52a0\u8f7dmoxing\u7684tensorflow\u6a21\u5757 moxing.tensorflow "}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "import moxing.tensorflow as mox\nimport os", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "\u6839\u636e\u6570\u636e\u5b58\u50a8\u548c\u6570\u636e\u8f93\u51fa\u8bbe\u7f6edata_url\u548ctrain_url"}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "####### your coding place\uff1a begin  ###########\n# \u6b64\u5904\u5fc5\u987b\u4fee\u6539\u4e3a\u7528\u6237\u6570\u636e\u6876\u4f4d\u7f6e\n\n#\u6570\u636e\u5728OBS\u7684\u5b58\u50a8\u4f4d\u7f6e\u3002\n# eg. s3:// \uff1a\u7edf\u4e00\u8def\u5f84\u8f93\u5165\n#     /uBucket \uff1a\u6876\u540d\uff0c\u7528\u6237\u7684\u79c1\u6709\u6876\u7684\u540d\u79f0 eg. bucket\n#     /notebook/data/\uff1a \u6587\u4ef6\u8def\u5f84\n\ndata_url = 's3://bucket/notebook/data/' \n\n####### your coding place\uff1a end  ###########", "execution_count": null, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "train_url = './cache/log/'          #\u8bad\u7ec3\u8f93\u51fa\u4f4d\u7f6e\u3002\nif not mox.file.exists(data_url):\n    raise ValueError('Plese verify your data url!')\nif mox.file.exists(train_url):\n    mox.file.remove(train_url,recursive=True)\nmox.file.make_dirs(train_url)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": " \u901a\u8fc7mox \u80fd\u591f\u5c06\u6570\u636e\u62f7\u8d1d\u5230\u672c\u5730\uff0c\u8fd9\u6837\u80fd\u591f\u52a0\u5feb\u8bad\u7ec3\u3002\u64cd\u4f5c\u5982\u4e0b\uff1a"}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "# \u672c\u5730\u521b\u5efa\u6570\u636e\u5b58\u50a8\u6587\u4ef6\u5939\nlocal_url = './cache/local_data/'\nif mox.file.exists(local_url):\n    mox.file.remove(local_url,recursive=True)\nos.makedirs(local_url)\n\n#\u5c06\u79c1\u6709\u6876\u4e2d\u7684\u6570\u636e\u62f7\u8d1d\u5230\u672c\u5730mox.file.copy_parallel\uff08\uff09\n\"\"\"\n  Copy all files in src_url to dst_url. Same usage as `shutil.copytree`.\n  Note that this method can only copy a directory. If you want to copy a single file,\n  please use `mox.file.copy`\n\n  Example::\n\n    copy_parallel(src_url='/tmp', dst_url='s3://bucket_name/my_data')\n\n  Assuming files in `/tmp` are:\n\n  * /tmp:\n      * |- train\n          * |- 1.jpg\n          * |- 2.jpg\n      * |- eval\n          * |- 3.jpg\n          * |- 4.jpg\n\n  Then files after copy in `s3://bucket_name/my_data` are:\n\n  * s3://bucket_name/my_data:\n      * |- train\n          * |- 1.jpg\n          * |- 2.jpg\n      * |- eval\n          * |- 3.jpg\n          * |- 4.jpg\n\n  Directory `tmp` will not be copied. If `file_list` is `['train/1.jpg', 'eval/4.jpg']`,\n  then files after copy in `s3://bucket_name/my_data` are:\n\n  * s3://bucket_name/my_data\n      * |- train\n          * |- 1.jpg\n      * |- eval\n          * |- 4.jpg\n\n  :param src_url: Source path or s3 url\n  :param dst_url: Destination path or s3 url\n  :param file_list: A list of relative path to `src_url` of files need to be copied.\n  :param threads: Number of threads or processings in Pool.\n  :param is_processing: If True, multiprocessing is used. If False, multithreading is used.\n  :param use_queue: Whether use queue to manage downloading list.\n  :return: None\n\"\"\"\nmox.file.copy_parallel(data_url, local_url)\ndata_url = local_url\nos.listdir(data_url)", "execution_count": null, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "from tensorflow.examples.tutorials.mnist import input_data\nimport tensorflow as tf\nfrom __future__ import print_function\nfrom __future__ import unicode_literals", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "**\u8bf4\u660e 1**  &#160; &#160; \u51fd\u6570 tf.flags.DEFINE_string('data_url', None, 'Dir of dataset')  \u6570\u636e\u8def\u5f84\u3002\n                  \u51fd\u6570tf.flags.DEFINE_string('train_url', None, 'Train Url') \u65e5\u5fd7\u4ee5\u53ca\u751f\u4ea7\u6a21\u578b\u7684\u5b58\u50a8\u8def\u5f84\u3002 \u5f53\u811a\u672c\u8fd0\u884c\u7684\u65f6\u5019\u53ef\u4ee5\u5229\u7528tf.flags\u4f20\u5165\u53c2\u6570\u3002"}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "tf.flags.DEFINE_string('data_url', None, 'Dir of dataset')\ntf.flags.DEFINE_string('train_url', None, 'Train Url')\n\nflags = tf.flags.FLAGS\n\nfilenames = ['train-images-idx3-ubyte.gz','train-labels-idx1-ubyte.gz','t10k-images-idx3-ubyte.gz',\n             't10k-labels-idx1-ubyte.gz']\n\nfor filename in filenames:\n  filepath = os.path.join(data_url, filename)\n  if not mox.file.exists(filepath):\n    raise ValueError('MNIST dataset file %s not found in %s' % (filepath, local_url))", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "####  &#160;&#160;\u8bad\u7ec3\u7684main\u51fd\u6570\u5305\u542b\u4e09\u4e2a\u90e8\u5206\uff0c\u8f93\u5165\u5b9a\u4e49\u3001\u6a21\u578b\u5b9a\u4e49\u548c\u8fd0\u884c\u3002\n\n1\uff09 \u8f93\u5165\u51fd\u6570\uff1ainput_fn(run_mode, **kwargs) \u7528\u6237\u53ef\u4ee5\u6839\u636e\u81ea\u5df1\u7684\u8f93\u5165\u7f16\u5199\u3002\u672c\u4f8b\u4e2d\u901a\u8fc7\u8fed\u4ee3\u7684\u65b9\u5f0f\u4ece\u6570\u636e\u96c6\u4e2d\u53d6\u6570\u636e\u3002\n\n\n2\uff09 \u6a21\u578b\u5b9a\u4e49\uff1adef model_fn(inputs, run_mode, **kwargs): \u6a21\u578b\u7ed3\u6784\u5b9a\u4e49\u51fd\u6570\uff0c\u8fd4\u56de mox.ModelSpec(\uff09\uff0c\u7528\u6237\u4f5c\u4e1a\u6a21\u5f0f\u5b9a\u4e49\u8fd4\u56de\u503c\u3002\n\u4f46\u9700\u8981\u6ee1\u8db3\u5982\u4e0b\u6761\u4ef6\uff1a\n\n &#160;&#160; For run_mode == ModeKeys.TRAIN: `loss` is required.\n  \n  &#160;&#160;  For run_mode == ModeKeys.EVAL: `log_info` is required.\n  \n  &#160;&#160;  For run_mode == ModeKeys.PREDICT: `output_info` is required.\n  \n  &#160;&#160;  For run_mode == ModeKeys.EXPORT: `export_spec` is required.\n  \n\n3\uff09 \u6267\u884c\u8bad\u7ec3\uff1a mox.run(\uff09\uff0c\u8bad\u7ec3\u7684\u8fc7\u7a0b\u4e2d\u53ef\u6307\u5b9aoptimizer\u7684\u4e00\u4e9b\u8bbe\u7f6e\uff0c\u8bad\u7ec3batch\u7684\u5927\u5c0f\u7b49\uff0c\u8bbe\u7f6e\u5185\u5bb9\u5982\u4e0b\uff1a\n\n\n &#160;&#160; \u8f93\u5165\u51fd\u6570\uff0c input_fn: An input_fn defined by user. Allows tfrecord or python data. Returns  input tensor list.\n \n &#160;&#160;  \u6a21\u578b\u51fd\u6570\uff0c model_fn: A model_fn defined by user. Returns `mox.ModelSpec`.\n  \n  &#160;&#160; optimizer\u5b9a\u4e49\uff0c optimizer_fn: An optimizer_fn defined by user. Returns an optimizer.\n  \n  &#160;&#160; \u8fd0\u884c\u6a21\u5f0f\u9009\u62e9\uff0c run_mode: Only takes mox.ModeKeys.TRAIN or mox.ModeKeys.EVAL or mox.ModeKeys.PREDICT\n  \n  &#160;&#160; batch\u5927\u5c0f\u8bbe\u7f6e\uff0c batch_size: Mini-batch size.\n  \n &#160;&#160;  \u662f\u5426\u81ea\u52a8\u5316batch\uff0c auto_batch: If True, an extra dimension of batch_size will be expanded to the first\n                     dimension of the return value from `get_split`. Default to True.\n                     \n  &#160;&#160; \u65e5\u5fd7\u4ee5\u53cacheckpoint\u4fdd\u5b58\u4f4d\u7f6e\uff0c log_dir: The directory to save summaries and checkpoints.\n  \n  &#160;&#160; \u6700\u5927\u6570\u91cf\uff0c  max_number_of_steps: Maximum steps for each worker.\n                          \n  &#160;&#160; \u65e5\u5fd7\u6253\u5370\uff0c log_every_n_steps: Step period to print logs to std I/O.\n     \n  &#160;&#160; \u662f\u5426\u8f93\u51fa\u6a21\u578b\uff0c export_model: True or False. Where to export model after running the job.\n\n"}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "def main(*args):\n  flags.data_url = data_url\n  flags.train_url = train_url\n  mnist = input_data.read_data_sets(flags.data_url, one_hot=True)\n        \n\n  # define the input dataset, return image and label\n  def input_fn(run_mode, **kwargs):\n    def gen():\n      while True:\n        yield mnist.train.next_batch(50)\n    ds = tf.data.Dataset.from_generator(\n        gen, output_types=(tf.float32, tf.int64),\n        output_shapes=(tf.TensorShape([None, 784]), tf.TensorShape([None, 10])))\n    return ds.make_one_shot_iterator().get_next()\n\n\n  # define the model for training or evaling.\n  def model_fn(inputs, run_mode, **kwargs):\n    x, y_ = inputs\n    W = tf.get_variable(name='W', initializer=tf.zeros([784, 10]))\n    b = tf.get_variable(name='b', initializer=tf.zeros([10]))\n    y = tf.matmul(x, W) + b\n    cross_entropy = tf.reduce_mean(\n      tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y))\n    predictions = tf.argmax(y, 1)\n    correct_predictions = tf.equal(predictions, tf.argmax(y_, 1))\n    accuracy = tf.reduce_mean(tf.cast(correct_predictions, tf.float32))\n    export_spec = mox.ExportSpec(inputs_dict={'images': x}, outputs_dict={'predictions': predictions}, version='model')\n    return mox.ModelSpec(loss=cross_entropy, log_info={'loss': cross_entropy, 'accuracy': accuracy},\n                         export_spec=export_spec)\n\n\n  mox.run(input_fn=input_fn,\n          model_fn=model_fn,\n          optimizer_fn=mox.get_optimizer_fn('sgd', learning_rate=0.01),\n          run_mode=mox.ModeKeys.TRAIN,\n          batch_size=50,\n          auto_batch=False,\n          log_dir=flags.train_url,\n          max_number_of_steps=1000,\n          log_every_n_steps=10,\n          export_model=mox.ExportKeys.TF_SERVING)\n\nif __name__ == '__main__':\n  tf.app.run(main=main)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## <a name=\"predict\">2. \u9884\u6d4b</a>  \n\n"}, {"metadata": {}, "cell_type": "markdown", "source": "&#8195;&#8195; \u5728\u4e0a\u9762\u8bad\u7ec3\u7684\u57fa\u7840\u4e0a\uff0c\u6211\u4eec\u53ef\u4ee5\u76f4\u63a5\u7528\u8bad\u7ec3\u7684\u6a21\u578b\u8fdb\u884c\u9884\u6d4b\u4f5c\u4e1a\u3002\u5982\u8bfb\u53d6OBS\u6876\u4e2d\u7684\u6570\u5b57\u56fe\u7247\u8fdb\u884c\u8bc6\u522b\u3002input_fn \u5bf9\u8f93\u5165\u56fe\u7247\u8fdb\u884c\u7b80\u5355\u5904\u7406\uff0c\u5f97\u5230\u7f51\u7edc\u5141\u8bb8\u7684\u8f93\u5165tensor\uff1bmodel_fn\u5b9a\u4e49\u4e00\u4e2a\u9884\u6d4b\u5185\u5bb9\uff0c\u540c\u65f6\uff0c\u8fd8\u9700\u5b9a\u4e49\u4e00\u4e2a\u5bf9\u8f93\u51fa\u5904\u7406\u7684\u51fd\u6570output_fn\uff0c\u6211\u4eec\u5728\u6539\u51fd\u6570\u91cc\u5bf9\u8f93\u51fa\u8fdb\u884c\u4e00\u4e2a\u6253\u5370\u8f93\u51fa\u3002\n \n  \u8fd8\u9700\u5728 mox.run()\u51fd\u6570\u4e2d\u52a0\u5165\u5982\u4e0b\u53c2\u6570\uff1a\n  \n &#8195;&#8195; \u8f93\u51fa\u51fd\u6570 output_fn: A callback with args of results from sess.run.\n   \n&#8195;&#8195; \u6a21\u578b\u52a0\u8f7d\u4f4d\u7f6e checkpoint_path: Directory or file path of ckpt to restore when `run_mode` is 'evaluation'.\n                          Useless when `run_mode` is 'train'."}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "####### your coding place\uff1a begin###########\n\n#\u6b64\u5904\u5fc5\u987b\u4fee\u6539\u4e3a\u7528\u6237\u6570\u636e\u5b58\u50a8\u7684OBS\u4f4d\u7f6e\n\n# \u9884\u6d4b\u56fe\u7247\u5728OBS\u7684\u5b58\u50a8\u4f4d\u7f6e\u3002\n# eg. \u56fe\u7247\u540d\u79f0\uff1a  image_number.jpg\n#     \u5b58\u50a8\u4f4d\u7f6e\u4e3a\uff1abucket/test/\nsrc_path = 's3://bucket/test/image_number.jpg'\n\n####### your coding place\uff1a end  ###########", "execution_count": null, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "# \u53ef\u4ee5\u5229\u7528moxing \u5c06\u9700\u8981\u9884\u6d4b\u7684\u56fe\u7247\u4eceOBS\u62f7\u8d1d\u5230\u672c\u5730\nif not mox.file.exists(src_path):\n    raise ValueError('Plese verify your src_path!')\ndst_path =  './cache/test.jpg'\nmox.file.copy(src_path,dst_path)", "execution_count": null, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "image_path = './cache/test.jpg'            # \u6307\u5b9a\u56fe\u7247\u4f4d\u7f6e\ncheckpoint_url = './cache/log/'         # \u6307\u5b9acheckpoint\u4f4d\u7f6e\uff0c\u5373\u4e0a\u4e00\u6b65\u8bad\u7ec3\u6307\u5b9a\u7684\u8def\u5f84\u7684\u4f4d\u7f6e\u3002\nprint(mox.file.exists(image_path))", "execution_count": null, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "import moxing.tensorflow as mox\nimport os\nimport tensorflow as tf\nfrom __future__ import print_function\nfrom __future__ import unicode_literals\n", "execution_count": null, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "def predict(*args):\n  def input_fn(run_mode, **kwargs):\n    image = tf.read_file(image_path)\n    img = tf.image.decode_jpeg(image, channels=1)\n    img = tf.image.resize_images(img, [28, 28], 0)\n    img = tf.reshape(img, [784])\n    return img\n\n  def model_fn(inputs, run_mode, **kwargs):\n    x = inputs\n    W1 = tf.get_variable(name='W', initializer=tf.zeros([784, 10]))\n    b1 = tf.get_variable(name='b', initializer=tf.zeros([10]))\n    y = tf.matmul(x, W1) + b1\n    predictions = tf.argmax(y, 1)\n    return mox.ModelSpec(output_info={'predict': predictions})\n\n  def output_fn(outputs):\n    for output in outputs:\n      result = output['predict']\n      print(\"The result\uff1a\",result)\n\n  mox.run(input_fn=input_fn,\n          model_fn=model_fn,\n          output_fn=output_fn,\n          run_mode=mox.ModeKeys.PREDICT,\n          batch_size=1,\n          auto_batch=False,\n          max_number_of_steps=1,\n          output_every_n_steps=1,\n          checkpoint_path=checkpoint_url)\nif __name__ == '__main__':\n  tf.app.run(main=predict)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "\u901a\u8fc7\u9884\u6d4b\uff0c\u6211\u4eec\u80fd\u591f\u770b\u5230\u7ed3\u679c\u8f93\u51fa\u3002\n"}], "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3", "language": "python"}, "language_info": {"name": "python", "version": "3.6.4", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat": 4, "nbformat_minor": 2}