本次实战我们使用的VOC2012数集，里面包含了五千左右的图片。做完实践后，上网百度下，了解到：（在计算视觉的领域中，Pascal VOC Challenge 就好比是数学中的哥德巴赫猜想一样。Pascal的全称是Pattern Analysis, Statical Modeling and Computational Learning。每年，该组织都会提供一系列类别的、带标签的图片，挑战者通过设计各种精妙的算法，仅根据分析图片内容来将其分类，最终通过准确率、召回率、效率来一决高下。）
目前最新的数据集是VOC2012数据集下载地址：http://host.robots.ox.ac.uk/pascal/VOC/voc2012/VOCtrainval_11-May-2012.tar
里面包含了17125个图片。上个实验训练了2个小时。建议这个训练睡前启动，第二天起来看结果吧。
下载的文件还是和案例一样操作把ImageSets（图像集）里面的文件和Annotations（注释）的文件合并在一起。合并完毕我进行了一次文件匹配查询，这是因为在ModelArts里面做训练图片文件和注释文件必须一一对应，否者会提示失败。这里平台有提示：
![](http://p1.pstatp.com/large/pgc-image/ecb2704828664bc7a4ab03078f9ba832)
那么如何保证没有错误，这里我提供了实战营里面的学友（几分快乐）同学提供的一段代码，我就借花献佛了，嘿嘿。

```
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
# xml 操作, 把数据标签统一化
# 注意,此程序会把给定目录下所有文件过滤一次
# 只保留 XXX.xml和与之相对应名字不同后缀名的文件
# 其余全部会移动到 ./trash 目录下
import os
import shutil

# 要去重的目录目录
DIR_PATH = "K:/AI/第四期/VOCtrainval_11-May-2012/VOCdevkit/VOC2012/mcqdata"
# 不存在配对文件挪动到这里
TRASH_PATH = "J:/gimg7/trash"

USED_XML_SET = set()
UNUSED_XML_SET = set()


def main():
    if not os.path.isdir(DIR_PATH):
        print("指定路径:", DIR_PATH, "不是文件夹")
        return
    for f_name in os.listdir(DIR_PATH):
        f_path = os.path.join(DIR_PATH, f_name)
        if os.path.isdir(f_path):
            continue
        elif f_name.endswith(".xml"):
            # 如果以 xml结尾,那么查看是否使用过,如果没使用过,那么挪入 UNUSED_XML_SET
            if not f_name in USED_XML_SET:
                UNUSED_XML_SET.add(f_name)
        else:
            # 不是xml文件,必须有一个xml与之对应,否则就挪入TARSH_PATH中
            xml_file_name = f_name.rstrip(os.path.splitext(f_name)[-1]) + ".xml"
            xml_file_path = os.path.join(DIR_PATH, xml_file_name)
            if not os.path.exists(xml_file_path):
                os.makedirs(TRASH_PATH, exist_ok=True)
                des_path = os.path.join(TRASH_PATH, f_name)
                shutil.move(f_path, des_path)
            else:
                USED_XML_SET.add(xml_file_name)
                if xml_file_name in UNUSED_XML_SET:
                    UNUSED_XML_SET.remove(xml_file_name)

    for f_name in UNUSED_XML_SET:
        file_path = os.path.join(DIR_PATH, f_name)
        des_path = os.path.join(TRASH_PATH, f_name)
        shutil.move(file_path, des_path)


# 启动main
if __name__ == '__main__':
    main()





```
在本地执行完这段代码后，就可以放心的上传到obs上进行训练了。
在第一次训练的时候出现了训练时间过长，obs奔溃的情况图：

![](http://p1.pstatp.com/large/pgc-image/eb220cb295884f5385c89e3fb551b508)

可以看出，当训练到550分钟左右后 我们的GPU就停止工作了。查询日志，也发现在第七轮训练的时候就没有继续。与华为专家沟通后，该问题应该是在训练的时候实时访问obs，定位出问题了，导致读取obs卡死。但是训练只要读不到数据，就一直等待。不会自动停止训练作业。那目前只能先停止了。重新再开一个训练把num_epoch修改为2。大概运行了2个小时结果如下：

![](http://p1.pstatp.com/large/pgc-image/4d28c38cd637429aa56809c347b88d3f)

我们再对比下07版的：

![](http://p3.pstatp.com/large/pgc-image/e18af23bbb344e778388dde81d6e9832)

可以看出在丰富的数据集下对训练结果有明显提高。但相对的训练时间也增加了很多。
如果要训练12版的建议不要超过6次。
