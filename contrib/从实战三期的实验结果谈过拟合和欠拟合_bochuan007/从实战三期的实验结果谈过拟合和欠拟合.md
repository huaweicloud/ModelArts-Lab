[【华为云 ModelArts-Lab AI实战营】第三期：图像分类 (III) 模型参数&网络调优](https://github.com/huaweicloud/ModelArts-Lab/issues/219#issue-463843079)

实验做完后，对过拟合和欠拟合以及现有AI框架的参数调整有了一些新的认识，写出来请各位同学指正

### 首先举个栗子，解释过拟合和欠拟合

假设我们在二维实数空间有一个点集P(x, y)如下图所示：

![华为测试2019070520](https://user-images.githubusercontent.com/9285301/60752950-c957e100-9ffe-11e9-9655-f3b46d62b369.jpg)

我们取靠近y轴的14个点作为训练集：

![华为测试2019070521](https://user-images.githubusercontent.com/9285301/60752958-eab8cd00-9ffe-11e9-968a-d8548ae1a67a.jpg)

注意前14个点中有3个明显的噪点是我故意加入的

那么现在我们训练一个模型来拟合训练集，在这个例子中就是找到一个函数h(x)可以尽量匹配已有的点集
下面是三种模型的可视化：

![华为测试2019070525](https://user-images.githubusercontent.com/9285301/60753022-af6ace00-9fff-11e9-8a29-1f0cf5a3995a.jpg)

黄色线代表的模型甚至没有和训练集拟合好，这属于欠拟合
蓝色的线和训练集拟合不错，而且在测试集上表现也不错，这是个不错的模型
绿色的线和训练集拟合的太好了，把噪点的特点也提取出来了，这属于过拟合

再来看看不错的模型和过拟合的模型在整个点集上的表现：

![华为测试2019070523](https://user-images.githubusercontent.com/9285301/60753061-328c2400-a000-11e9-95eb-479316859c13.jpg)

可以明显看出过拟合的模型一旦超出训练集（前14个点）的范围，预测的结果和期望值（点集P）相差过大，属于不能用的模型

公布一下蓝色的线代表的函数 y = 2.8 + 2.2 * x
绿色的线代表的函数 y = 2.8 + x * 2.3 + (x ** 2) * 1.1  + (x ** 3) * -0.35 + (x ** 4) * 0.0235 + (x ** 5) * -0.000001

### 根据leewishyuanfang的回帖做个修改：
以上的的例子属于线性回归的例子，多举一个针对分类问题（逻辑回归）的例子

首先，准备一下数据：

![华为测试2019070526](https://user-images.githubusercontent.com/9285301/60755583-7133d580-a024-11e9-880d-5d0505e5e29d.jpg)

有两个点集P1(蓝色)和P2(绿色),现在要想办法学习一个模型判断一个点是否属于蓝色点

将x=5这条直线左边的部分作为训练集

![华为测试2019070527](https://user-images.githubusercontent.com/9285301/60755690-ab51a700-a025-11e9-9ac4-b77c0c7efd15.jpg)

那么，欠拟合的情况是这样的：

![华为测试2019070528](https://user-images.githubusercontent.com/9285301/60755697-d89e5500-a025-11e9-9d6e-10c6d26eed52.jpg)

橙色圈代表一个训练出的模型，这个模型认为橙色圈内的部分属于蓝色点

而一个不错的模型是这样的：

![华为测试2019070528-1](https://user-images.githubusercontent.com/9285301/60755714-36cb3800-a026-11e9-9a02-d582414356bf.jpg)

过拟合的逻辑回归模型是这样的：

![华为测试2019070528-2](https://user-images.githubusercontent.com/9285301/60755734-87db2c00-a026-11e9-9833-16081ba0e03c.jpg)

当然，实际情况很少过拟合的这么夸张

在3期实训过程中，可以明显发现过拟合的情况

![image](https://user-images.githubusercontent.com/9285301/60753215-aed33700-a001-11e9-8be0-b482b178a581.png)

![image](https://user-images.githubusercontent.com/9285301/60753222-d2967d00-a001-11e9-95ae-ccec1ce6c96a.png)

![image](https://user-images.githubusercontent.com/9285301/60753238-02458500-a002-11e9-8a05-472ff98e79dc.png)

![image](https://user-images.githubusercontent.com/9285301/60753258-1be6cc80-a002-11e9-9c14-37888f91a68d.png)

### 过拟合在实际模型训练中表现为：模型在训练集上的准确率（acc）不断上升的过程中，模型在验证集上的准确率（val_acc）缺下降了

### 发生的原因可总结为模型训练的过程中，在训练集中提取了并非是共性的特征并分配了过高的权重


但使用随机梯度下降的31epoch过程中，出现的情况和我的设想不同

我设想的acc和val_acc之间的关系应该是下图：

![image](https://user-images.githubusercontent.com/9285301/60753383-f0fd7800-a003-11e9-8222-c6c96eecf656.png)

随着在训练集中提取的个性越来越多（学习偏见越来越大），acc越来越高，经过一个短线的震荡，val_acc应该出现断崖式的下跌

但实际情况是：

![华为测试2019070513](https://user-images.githubusercontent.com/9285301/60753398-3ae65e00-a004-11e9-9fd8-203d70b31a82.jpg)

这个算法在acc越来越高的情况下，val_acc也出现了震荡，但震荡保持的轮次很长，甚至直到完成31轮epoch都没有出现断崖式的下跌

我现在的理解是，这个算法在acc提升的过程中，主动调低了导致val_acc明显下降的特征权重。

### @leewishyuanfang 对val_acc并没有出现断崖式下跌做出了如下解释，我觉得可以完全解释我的问题：

首先，以你的解释欠拟合和过度拟合的例子来说，在这个例子中，加入的3个噪声的影响是巨大的，从总数来说，三个噪声占到了所有样本的20%以上，而且在分布上太过于集中，所以对于最终学习到的曲线的影响是特别大，导致过度拟合时整个曲线在后期发生了巨大的变化，与期望曲线相距甚远。

而在本次猫狗识别的例子中，训练集中有18750张图片，其中属于明显异常的噪声图片可能并没有达到如此高的比例（这里仅是推断），此外，由于在训练时，每次提取的一个batch样本均是随机提取的，所以也在很大方面上避免了噪声过于集中的问题，所以发生过度拟合时，出现的情况是在验证集上的val_acc出现震荡，但并不会出现断崖式的下跌，毕竟训练集和验证集的差别并不大。
