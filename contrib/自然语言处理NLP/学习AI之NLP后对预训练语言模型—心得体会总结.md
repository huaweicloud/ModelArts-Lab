## 一、学习NLP背景介绍:
   从2019年4月份开始跟着华为云ModelArts实战营同学们一起进行了6期关于图像深度学习的学习，初步了解了关于图像标注、图像分类、物体检测，图像都目标物体检测等，基本了解了卷积神经网络(CNN)原理及相关常用模型，如：VGG16、MaxNet等。之后从9月份开始在华为云AI专家的带领指引下，对AI深度学习的另外一个重要领域：自然语言处理（NLP）的学习，到目前为止学习了：命名实体识别、文本分类、文本相似度分析、问答系统、人脸检测。在这一个多月对NLP的处理流程，常用模型及原理进行了初步了解及理解，到目前还只是部分理解，不能全部吃透，感觉比前期图像领域的深度学习理论知识复杂及难理解很多，主要是体现在图像领域有很多图像架构暂时原理及公司推导；而NLP这方面比较少，为了在这1个多月对NLP的理解及后期帮助复习巩固，以下对NLP领域的相关只是根据自己的理解及网上相关知识做整理和归纳。
### 2、Baseline从头开始
首先，由于时间紧迫，报名后加紧学些比赛规则、流程，然后从官方下载代码，数据集，大概看了下数据集为数量，并将数据集按9：1分成训练集和测试集，并按照官方提供的基本代码跑了一次（基本参数：ResNet50,batch_size=32,learning_rate=1e-4,epochs=10），在训练中，数据集和验证集的进度都非常高，达到98%以上，但最后对测试集进行验证模型好坏，得到进度缺只有69%左右，思考后觉得是不是数据集太少，模型复杂，导致容易出现过拟合问题，然后将模型采用熟悉的VGG16并采用Dropout防止过拟合，最后训练进度提升到73%，如下图：
<img src="./imgs/VGG-1-0.jpg">
<img  src="./imgs/vgg-1-1.jpg"><br>
### 2. 如何在现有数据集基础上提高模型精度
