基于第一期notebook猫狗识别实例将vgg16算法改用resnet50算法以求提高准确度。以下是我测试过程中的一些经验(错误之处希望提出更正)：
该算法预训练权值由 Kaiming He 发布的预训练权值移植而来，基于 MIT license。
resnet50算法的图片宽高必须在32以上，在resnet50算法参数中include_top设置成Flase,即不包括顶层的全连接层（曾将它修改成True，发现准确度大幅下降至50%以下）
神经网络改为用keras构建resnet50卷积神经网络,代码：base_model = ResNet50(weights="imagenet", include_top=False, pooling=None, input_shape=(ROWS, COLS, CHANNELS), classes=2)它将会访问并下载
https://github.com/fchollet/deep-learning-models/releases/download/v0.2/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5
下载速度受本地网速影响，至于华为云下载速度还是蛮快的
由于这个模型需要的训练参数比较多以至于速度比较慢我就把轮数epochs改为30,batch_size=30,学习率修改为le-4
以下是需要(除了第一期notebook本身的)另外引用的一些库
import tensorflow as tf
from keras.models import load_model
from keras.preprocessing import image
from keras.utils import layer_utils
from keras.utils.data_utils import get_file
from keras.applications.imagenet_utils import preprocess_input
from IPython.display import SVG
from keras.utils.vis_utils import model_to_dot
from keras.callbacks import Callback, EarlyStopping, TensorBoard
from keras.applications.resnet50 import ResNet50
from keras import optimizers
from keras.layers import Input, Dropout, Flatten, Conv2D, MaxPooling2D, Dense, Activation,BatchNormalization,GlobalAveragePooling2D
以下是具体代码以及训练过程

升级依赖：!pip install --upgrade keras_applications==1.0.6 keras==2.2.4
引用依赖库:
import os, cv2, random
import numpy as np

# 画图工具
import matplotlib.pyplot as plt
import seaborn as sns
%matplotlib inline

from keras.layers import Input, Dense
from keras.optimizers import RMSprop
from keras.callbacks import Callback, EarlyStopping, TensorBoard
from keras.models import Model
from keras.utils import np_utils

from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
import tensorflow as tf
from keras.models import load_model
from keras.preprocessing import image
from keras.utils import layer_utils
from keras.utils.data_utils import get_file
from keras.applications.imagenet_utils import preprocess_input
from IPython.display import SVG
from keras.utils.vis_utils import model_to_dot
from keras.callbacks import Callback, EarlyStopping, TensorBoard
from keras.applications.resnet50 import ResNet50
from keras import optimizers
from keras.layers import Input, Dropout, Flatten, Conv2D, MaxPooling2D, Dense, Activation,BatchNormalization,GlobalAveragePooling2D
from keras import backend as K
K.set_image_data_format('channels_last')
运行结果：Using TensorFlow backend.
下载数据集
DATA_DIR = './data/'  # 数据集路径
OUTPUT = './output/' # 模型保存位置
if not os.path.exists(DATA_DIR):
    os.makedirs(DATA_DIR)
if not os.path.exists(OUTPUT):
    os.makedirs(OUTPUT)

# 下载数据集
from modelarts.session import Session
session = Session()

session.download_data(
    bucket_path="modelarts-labs/notebook/DL_image_recognition/image_recognition.tar.gz",
    path="./image_recognition.tar.gz")

# 使用tar命令解压资源包
!tar xf ./image_recognition.tar.gz

# 清理压缩包
!rm -f ./image_recognition.tar.gz
ROWS = 228
COLS = 228
CHANNELS = 3
运行结果：Successfully download file modelarts-labs/notebook/DL_image_recognition/image_recognition.tar.gz from OBS to local ./image_recognition.tar.gz
tar: data: Cannot utime: Operation not permitted
tar: data: Cannot change mode to rwsr-s---: Operation not permitted
tar: Exiting with failure status due to previous errors
读取数据集：
image_file_names = [DATA_DIR+i for i in os.listdir(DATA_DIR)] 
dogs = [DATA_DIR+i for i in os.listdir(DATA_DIR) if 'dog' in i]
cats = [DATA_DIR+i for i in os.listdir(DATA_DIR) if 'cat' in i]

# 数据洗牌
random.shuffle(image_file_names)

def read_image(file_path):
    img = cv2.imread(file_path, cv2.IMREAD_COLOR) # 彩色模式读取图像
    return cv2.resize(img, (ROWS, COLS), interpolation=cv2.INTER_CUBIC)

def prep_data(image_file_names):
    count = len(image_file_names)
    data = np.ndarray((count, ROWS, COLS, CHANNELS), dtype=np.uint8)

    for i, image_file in enumerate(image_file_names):
        image = read_image(image_file)
        data[i] = image
        if i%1000 == 0: print('Processed {} of {}'.format(i, count))

    return data

# 读取图片至内存
images = prep_data(image_file_names)
运行结果：
Processed 0 of 25000
Processed 1000 of 25000
Processed 2000 of 25000
Processed 3000 of 25000
Processed 4000 of 25000
Processed 5000 of 25000
Processed 6000 of 25000
Processed 7000 of 25000
Processed 8000 of 25000
Processed 9000 of 25000
Processed 10000 of 25000
Processed 11000 of 25000
Processed 12000 of 25000
Processed 13000 of 25000
Processed 14000 of 25000
Processed 15000 of 25000
Processed 16000 of 25000
Processed 17000 of 25000
Processed 18000 of 25000
Processed 19000 of 25000
Processed 20000 of 25000
Processed 21000 of 25000
Processed 22000 of 25000
Processed 23000 of 25000
Processed 24000 of 25000
给图片打标签

num_train_samples = len(image_file_names)
num_classes = 2
labels = []

index = 0
for i in image_file_names:
    if 'dog.' in i:
        labels.append(1)
    else:
        labels.append(0)

# 把类别标签转换为onehot编码
labels = np_utils.to_categorical(labels, num_classes)
数据集切分
train_data, test_data, train_label, test_label = train_test_split(images, labels, test_size=0.25, random_state=10)
train_data, validate_data, train_label, validate_label = train_test_split(train_data, train_label, test_size=0.25, random_state=10)
查看样本图片
def show_cats_and_dogs(idx):
    cat = read_image(cats[idx])
    dog = read_image(dogs[idx])
    pair = np.concatenate((cat, dog), axis=1)
    plt.figure(figsize=(10,5))
    plt.imshow(pair)
    plt.show()

for idx in range(0,3):
    show_cats_and_dogs(idx)
设置超参
batch_size = 18 # 批大小
learning_rate = 1e-4 # 设置学习率为1e-4
优化器：
optimizer = RMSprop(lr=learning_rate) # 优化器使用 RMSprop
# Loss记录
class LossHistory(Callback):
    def on_train_begin(self, logs={}):
        self.losses = []
        self.val_losses = []

    def on_epoch_end(self, batch, logs={}):
        self.losses.append(logs.get('loss'))
        self.val_losses.append(logs.get('val_loss'))
def run_catdog():
    history = LossHistory()
    # 开始训练
    history=model.fit(train_data, train_label,
              epochs=epochs, batch_size=batch_size,
              verbose=2,shuffle=True,validation_data=(validate_data,validate_label),callbacks=[history, early_stopping])
    return history
用resnet50算法构建卷积层神经网络
base_model = ResNet50(weights="imagenet", include_top=False, pooling=None, input_shape=(ROWS, COLS, CHANNELS), classes=2)
# 冻结base_model所有层，这样就可以正确获得bottleneck特征
for layer in base_model.layers:
    layer.trainable = False
x = base_model.output
#添加自己的全链接分类层
x = Flatten()(x)

x = Dense(1024, activation='relu')(x)
x = Dropout(0.5)(x)
predictions = Dense(2, activation='softmax')(x)
#训练模型
model = Model(inputs=base_model.input, outputs=predictions)
运行结果：
Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.2/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5
94658560/94653016 [==============================] - 573s 6us/step
查看模型
model.summary()
运行结果：
（此处省略上方）
Total params: 157,808,514
Trainable params: 134,220,802
Non-trainable params: 23,587,712
________________________________________________________________________________________

模型训练：
epochs = 30
model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])
#######早停设置
early_stopping = EarlyStopping(monitor='val_loss', patience=3, verbose=1, mode='auto')

history = run_catdog()
# 训练好的模型可以保存起来，永久使用

model.save(os.path.join(OUTPUT, 'model.h5'))

运行结果：
Train on 14062 samples, validate on 4688 samples
Epoch 1/30
 - 72s - loss: 7.9216 - acc: 0.5046 - val_loss: 8.0391 - val_acc: 0.4985
Epoch 2/30
 - 64s - loss: 1.1527 - acc: 0.9183 - val_loss: 0.5381 - val_acc: 0.9605
Epoch 3/30
 - 63s - loss: 0.4532 - acc: 0.9667 - val_loss: 0.2518 - val_acc: 0.9821
Epoch 4/30
 - 63s - loss: 0.4043 - acc: 0.9704 - val_loss: 0.5371 - val_acc: 0.9629
Epoch 5/30
 - 63s - loss: 0.3759 - acc: 0.9734 - val_loss: 0.6072 - val_acc: 0.9582
Epoch 6/30
 - 63s - loss: 0.3367 - acc: 0.9762 - val_loss: 0.4124 - val_acc: 0.9721
Epoch 00006: early stopping
可视化训练模型：
loss = history.history['loss']
val_loss = history.history['val_loss']

plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.title('VGG-16 Loss Trend')
plt.plot(loss, 'blue', label='Training Loss')
plt.plot(val_loss, 'green', label='Validation Loss')
plt.xticks(range(0, epochs)[0::2])
plt.legend()
plt.show()

acc = history.history['acc']
val_acc = history.history['val_acc']

plt.xlabel('Epochs')
plt.ylabel('acc')
plt.title('VGG-16 acc Trend')
plt.plot(acc, 'blue', label='Training acc')
plt.plot(val_acc, 'green', label='Validation acc')
plt.xticks(range(0, epochs)[0::2])
plt.legend()
plt.show()

样本数据预测：
predictions = model.predict(test_data, verbose=0)
for i in range(0,10):
    p = predictions[i]

    if round(p[1]) == 1: 
        print('I am {:.2%} sure this is a Dog'.format(p[1]))
    else: 
        print('I am {:.2%} sure this is a Cat'.format(1 - p[1]))

    plt.imshow(test_data[i])
    plt.show()
 运行结果：
 I am 100.00% sure this is a Cat
 I am 100.00% sure this is a Dog
  I am 100.00% sure this is a Cat
 I am 100.00% sure this is a Dog
 I am 100.00% sure this is a Cat
 I am 100.00% sure this is a Dog
 I am 100.00% sure this is a Dog
  I am 100.00% sure this is a Cat
 I am 100.00% sure this is a Dog
 I am 100.00% sure this is a Dog
评估模型准确度：
# 预测测试集
predictions = model.predict(test_data, verbose=0)
# 评估模型准确度
predictions_test = []
test_label_test = []
for p in predictions:

    if int(round(p[0])) == 1:
        predictions_test.append(1)
    else:
        predictions_test.append(0)
for t in test_label:
    if int(t[0]) == 1:
        test_label_test.append(1)
    else:
        test_label_test.append(0)
acc = accuracy_score(test_label_test, predictions_test)

print('训练得到的猫狗识别模型的准确度是：%f' % acc)
运行结果：
训练得到的猫狗识别模型的准确度是：0.970720