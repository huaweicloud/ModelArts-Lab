# 华为云垃圾分类大赛心得与案例分享
赛事链接如下[https://developer.huaweicloud.com/competition/competitions/1000007620/introduction]
## 探索历程
### 1. Baseline开始
最开始入手是采用官方提供的baseline,按部就班的把数据上传,code上传,run一波,结果训练集合上0.99+,验证集合上0.99+,第一反应什么情况，这是要上天!!!然后，部署发布提交实际上准确率只有0.65左右，仔细查验官方baseline代码，发现官方代码存在个小bug，在多个文件中将loss写成了二分类loss，```objective = 'binary_crossentropy'```导致keras评估验证集合准确率错误，无法给出正确的评估。通过查验，发现对于多分类问题应该采用多分类交叉熵，```objective = 'categorical_crossentropy'```，立时修改，终于准确率评估正常了,至此baseline code成功跑通。
### 2. 思考提高
#### 2.1 简单改模型
baseline跑通了，那么怎么提高分数呢？第一反应改模型，开始魔改模型，首先对Resnet50模型后面添加多个全连接层，代码如下<br>
```
base_model = ResNet50(weights="imagenet",
                      include_top=False,
                      pooling=None,
                      input_shape=(FLAGS.input_size, FLAGS.input_size, 3),
                      classes=FLAGS.num_classes)
for layer in base_model.layers:
    layer.trainable = False
x = base_model.output
x = Flatten()(x)
x = Dense(256, activation='relu', kernel_regularizer=regularizers.l2(0.0001))(x)
x = Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.0001))(x)
predictions = Dense(FLAGS.num_classes, activation='softmax')(x)
model = Model(inputs=base_model.input, outputs=predictions)
model.compile(loss=objective, optimizer=optimizer, metrics=metrics)
```

通过增加epochs数量，调节learning rate进行训练。然而，由于数据数量较少总的不到20000张图片，发现epochs大了基本会存在过拟合，进一步引入early stop，和learning 调节的机制。代码如下:<br>
```
reduce_lr = ReduceLROnPlateau(monitor='val_acc', factor=0.2, patience=2, verbose=0, mode='auto', cooldown=0, min_lr=0)
early_stop = EarlyStopping(monitor='val_acc', patience=2, verbose=0, mode='auto')
model.fit_generator(
    train_sequence,
    steps_per_epoch=len(train_sequence),
    epochs=FLAGS.max_epochs,
    verbose=1,
    callbacks=[history, tensorBoard, reduce_lr, early_stop],
    validation_data=validation_sequence,
    max_queue_size=10,
    workers=int(multiprocessing.cpu_count() * 0.7),
    use_multiprocessing=True,
    shuffle=True
)
```

这样一套尝试下来，模型准度基本上可以提高到0.74左右。<br>
#### 2.2 模型架构更改
上述的做法提高的0.74后始终无法提升，考虑换个模型试试。参考过去的图像分类SOTA，发现keras提供了大量优秀的模型如NASNet，Inception，Xception等等。于是乎改模型架构的想法自然而然的诞生了。尝试了多种模型，但是奇怪的是在验证集合上的准确率始终停留在0.02~0.04基本处于瞎猜的水准。开始认为是图像处理的问题，对图像进行了```scale=1/255```，然而尽管验证准确率提高在测试准确率仍然停留在上述水平，百思不得其解最后上述思路，只得告吹。此番尝试，发现VGG，ResNet，MobileNet的模型可以尝试，但进一步尝试发现MobileNet，VGG的效果实际上还不如ResNet，最后只能继续基于ResNet进行考虑。
#### 2.3 ResNet更深的模型
既然其他模型不行，ResNet模型可以，那么更深的ResNet是不是可以获得更好的结果呢？出于这个考虑，立时考虑将ResNet50改为ResNet152。通过keras官方文档查阅知道keras.applications里由ResNet152。于是乎，马上动手改模型，将```from models.resnet50 import ResNet50```改为了```from keras.applications import ResNet152```并将模型改为了ResNet152。<br>
奇怪的事情又发生了，本地训练没有问题但是传上OBS创建训练作业，报错显示不存在模块ResNet152。无奈只好继续度娘，最后发现是ModelArts上keras-applications和keras版本低于官方文档的版本。好吧，那训练作业则么升级库？又不能像开发环境里直接```!pip install xxx ```。此处参考了ModelArt的官方文档,链接如下。[https://support.huaweicloud.com/modelarts_faq/modelarts_05_0063.html]
通过官方文档发现，需要在模型文件下引入pip-requirements.txt,进行依赖的安装升级，这里引入keras==2.2.5，keras-applications==1.0.8。然后ResNet152模型就可以上线了。<br>
此处实践会发现问题二，就是模型的预训练参数文件无法下载读取。通过查询，知道是训练作业过程无法连接外部网络，因此没法从Github上拉权重数据下来。因此只能对文件再次魔改一番，引入pretrained相关参数和在OBS和云之间的文件交互，从而读取预先下载好的传到OBS上的权重。通过这样一波改造，再训练基本上可以到0.8左右的准确率。那么问题是是否还能够提高呢？
#### 2.4 预训练上的思考
原始的预训练采用的思路是冻结了特征提取，并对最后加的两层Dense layer分类器进行训练，实际上并没有对特征提取进行调节。基于这个思路萌发了改造原始的代码训练最后5层的特征抽取和分类器训练，实际效果上可以发现有所提高，但是提高的不大，大概有1-2个点的提升。那么能否打开整个模型进行训练呢？思路上，感觉是可以得。但是目前的数据只有1.5W左右，训练整个模型数据量偏小，同时观察存在类别不均衡的情况，于是乎再进一步魔改做个数据增强，平衡一下类别，通过ImageDataGenerator将数据量增强到了70000多张图片，同时也缓解了类别不均衡问题。
于是乎在上述数据上再次训练，这次由于是采用全部打开的结构，训练时间非常长，所以架构上采用了ResNet50进行训练，差不多用了2个小时多在4*P100上训练（等价于8个小时在一个P100上训练），然后可喜的是模型获得了极大的提高准确率达到了0.86以上。
## 问题总结
目前的尝试中主要遇到了三个问题<br>
- 1. 改模型后准确率不正确，好吧这个问题最后还是没解决。
- 2. 引入keras.applications发现版本低的问题，最终通过引入pip-requirements.txt,进行依赖的安装升级。
- 3. 在最后的大模型上，选择了4*P100训练，但是发现部署不上，最后选择了单个P100训练
## 代码部分
本文将代码放在了同一文件夹下，放置的代码为ResNet50全开训练代码。
