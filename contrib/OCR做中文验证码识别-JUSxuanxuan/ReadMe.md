# OCR程序的实际应用案例

(先上传字体下载链接，因为不会传只能上传网盘了哈，将这个字体和CNN、CRNN放在一起就可以了，[地址](https://pan.baidu.com/s/19obLcEAbwuBJouD986biXg)   提取码c398 ) 

在GIthub上找到了一个大神的ocr程序，是做验证码的识别~~，拿出来分享给大家，很厉害，[地址]( https://github.com/ypwhs/captcha_break )。

那么我要做的就是在人家的基础上去做一个中文验证码的识别模型，数据集来自于咱们华为云16期的keys。

## 第一步：分析人家的代码模型

大概分析了下，两个方法：一个是cnn即利用类似于图像分类的思想，对验证码的每个进行分类；第二个是cnn+rnn+ctc也就是crnn模型。

#### cnn部分

①：数据集的生成：用的是keras中的Sequence这样的一个数据生成器（受用很多）；

②：标签矩阵的构建：验证码的标签是一个数组，可以这么理解：每一层是一个验证码，每一层有n_classes行，len(characters)列，n_classes代表这张图片中有几个字符，characters代表字符有多少个，因此得到每一张验证码的标签。举个例子，我要生成10张验证码，每一张图片中有4个字符，而字符来自于某个拥有5530个汉字的数据集，那么标签矩阵就是（4 x 10 x 5330）的一个三维矩阵，所以在但看一张图片时要固定y轴，去解读（x,z）两个轴。再仔细一点就是第一张图片是‘一二三四’（假设其对应的位置是四三一二）那么第一张图片的标签矩阵就是（1，1，4），（2，1，3），（3，1，1），（4，1，2）这样的一个矩阵。

③：标签矩阵的编码：注意，大神的项目编码是uint8，只能在255个之内，因此这这个模型并不适用于当汉字数据集很多的时候。

④：模型的构造：和vgg16很相似，卷积、标准化、激活函数、池化、核心网络层以及最后的全连接层

⑤：模型的训练：用的是fit_generator这样的训练函数，一代一代的训练，不用一下子生成好多数据集(很有用)。

⑥：概率矩阵的构建：和标签矩阵很类似。

#### crnn部分

①：数据集的生成：用cnn很类似也是Sequence，不过多了几个参数；

②：标签的构建：这个和cnn不一样，举个例子，要生成10个图片验证码，每个验证码中有4个字符串，那么最后得到的标签矩阵时（10  x 4），即对于第一张图片上的字是‘一二三四’（假设对应的位置是四三二一），那么对于第一个位置的图片这个标签向量就是（4，3，2，1）；

③：标签矩阵的编码：同样需要注意数据集的大小，uint8的范围；

④：模型的构造：和cnn的类似，但是加了ctc损失函数，以及时间循环迭代层；

⑤：模型的训练：同样用的是fit_generator；

⑥：概率矩阵的构建：也和cnn不一样，假设生成10个图片，字符来自于某个拥有100个字的数据集，那么出来的概率矩阵就是（10 x 16 x 100）这样的概率矩阵。





## 第二步：改动中文字符验证码的识别程序主要步骤

①：若想改变验证码的长度，只需要改掉这个n_len即可；

![image](https://user-images.githubusercontent.com/50792908/68101273-bea74d00-ff07-11e9-9344-42d916cea789.png)



②：数据集的定义在characters中改变就可以

![image](https://user-images.githubusercontent.com/50792908/68101281-c961e200-ff07-11e9-843a-147fe1c0c01b.png)

③：因为时间问题设置的epoch都很少，如果有兴趣可以改一改。

④：程序生成中文验证码需要字体设置，因此需要下载字体到同一目录下







## 第三步：中文字符验证码的识别代码实现步骤

#### [CNN部分]()

由于不太熟悉，因此拆成四部分由简单到困难的去做，在cnn模型中有四部分，分别是：

###### STEP1.对’一到九‘这九个字体选取一个字进行预测验证码模型的构建；

###### STEP2.自带数据集中的key中选取一个字进行预测验证码模型的构建；

###### STEP3.对‘一到九’这九个字体中选取四个字进行预测验证码模型的构建；

###### STEP4.自带数据集中的key中选取四个字进行预测验证码模型的构建；

在模型上改进方面需要用到的技术点

1.字体的导入(原模型的captcha库默认字体无法识别中文，需要导入字体指定参数)；

2.对原模型某些参数的修改；

#### [CRNN部分]()

这一部分是拆成了三个小部分

###### STEP1.对‘一到九’这九个字体中选择四个进行模型构建；

###### STEP2.对keys中的数据集抽取20个左右的字体选取四个进行模型构建；

###### STEP2.对keys整个数据集进行模型构建；

## 第四步：模型的效果

这里只展示正确率，具体的效果请看Jupyter Notebook

### cnn部分

效果图：

![image](https://user-images.githubusercontent.com/50792908/68101204-63755a80-ff07-11e9-95c2-5dfffb498b7a.png)



准确率
![image](https://user-images.githubusercontent.com/50792908/68101196-5b1d1f80-ff07-11e9-9df0-7ccbccfe0ce6.png)



### crnn部分

效果图
![image](https://user-images.githubusercontent.com/50792908/68101219-74be6700-ff07-11e9-85d8-7b6f8a9480ef.png)



准确率

![image](https://user-images.githubusercontent.com/50792908/68101231-856edd00-ff07-11e9-8846-59438fd63853.png)


简单总结
crnn在训练四次是85%，cnn训练5次是85%，因此crnn比cnn要好一些









## 第五部分：模型的不足：

①：只能识别定长验证码，即如果我的模型训练时是用4个中文字符训练的，它只能预测4个字符的验证码；

②：模型准确率有待提高；

③：感觉训练时间 ~~ 有点长 ~~~~；

④：由于uint8的范围在【0，255】，所以数据集内的汉字不可以超过255个~~

## 第六部分：提升模型的方法

①：数据集的收集，在日常碰到验证码时一般都是一些较为常见的汉字，keys中的汉字有一部分很难见到，因此如果全用keys中的数据集模型效果不好；

②：模型的代码优化：在代码方面可以更加简洁，某些参数可以更加节省内存；

③：预训练文件的导入，在模型构造时有预训练文件会好很多；

[项目地址](https://github.com/JUSxuaxuan/OCR-one/tree/master/OCR%E5%81%9A%E4%B8%AD%E6%96%87%E9%AA%8C%E8%AF%81%E7%A0%81)




























