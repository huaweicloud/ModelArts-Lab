| Author | Contact          | Date      | Version | Action  |
|-------:|-----------------:|----------:|--------:|--------:|
| Yi     | yiak.wy@gmail.com| 2019.6.20 | 0.1     | Created |

## ModelArts User Experience

ModelArts 由企业服务，--包括依托已有云计算\(对象存储，网盘，虚拟机计算资源调度\)等存储，计算服务，提供AI算力（GPU）和资源（AI市场, 开发者SDK）。本文通过成熟的从业经验，以及相关竞品分析，初探ModelArts，并分析目前已经服务的优势和不足，为进一步发展提供策略支持。

本文首先回顾几个重要产品的使用过程，并以此为契机，按图索骥分析并查找相关服务；然后本文在重要的相关功能上对市场已有的竞品，做分析和比较，得出目前的产品特点。ModelArts提供了"AI全流程开发"，开发者可以上传数据，在线标注，并部署公有云上，提供对外服务。用户上传数据后，一方面可以通过"自动服务"，完成特定训练目标的架构搜索并自动调参；另一方面可以在家利用华为云的资源创建Notebook，进行项目构建。目前项目构建还有有许多局限性，文后将通过代码，项目对比详细论述。ModelsArts，在另一方面对机器学习开发的支持还缺少一些产品支持, 比如具体视觉检测，自然语言等问题的"Model Hub"；常见数据集的导入，共享；以及项目本身分享机制缺失。

## Cloud Environment

其中对象存贮，磁盘的API，还不能再ModelArts notebook可编程地触手可及。作为对比，我们将分析Google Colab, Baidu AIStuidio等产品的特点。

在Google Colab实验中[Colab book](https://colab.research.google.com/drive/1A5ZoDc9PhYq_Rgvz8C8gPe8N5bWoo4xk)，以及[Github](https://github.com/yiakwy/SpatialPerceptron/blob/master/notebooks/prepare_colab.ipynb)大数据文件，可以在不同的磁盘地址存贮，并Mount到指定位置, 即云磁盘挂载。同时Google提供了SDK, 统一定义到云客户端IO包空间，方便客户端用户在远端通过对象存储，云磁盘API进行数据上传和下载。目前ModelArts，可以通过Model Session API在远端完成数据加载任务，但这方面的SDK支持并不完善，没有形成针对客户端，远端统一的IO工具集成，有进一步发力空间。

在现代AI技术下，notebook不仅可以运行python程序，也可以运行C++程序。同时Notebook可以同步远端主机操作，因此可以成为一个实际上虚拟机的控制端口。在上面我们可以下载，编译，复杂程序，这更符合现代以深度学习模型和核心的视觉，自然语言技术的实际需求。本文在[AIStudio book](https://aistudio.baidu.com/aistudio/projectdetail/60969)提供了一套，切实可行的构建方法，方便用户在实际为docker容器的Jupyter notebook坐在的虚拟机中进行软件构建。

以Modelarts为例，虽然已经配置了make, openssl, curl, perl但还缺乏很多必要的开发套件，且用户主机为根目录挂载磁盘并不持久化。由于缺乏sudo权限，不熟悉LINUX软件栈的用户，就难以根据需求开发复杂的应用程序。比如已知缺乏git, nvidia-smi等，不方便想下载以及，显存释放管理。

## AutoML

AutoML是依托于强化学习的一种模型检索技术，也是第一次将深度学习应用多整数规划的算法实例。决策者可以根据自己的需求设计激励函数，或者规则，并通过集成的检索，优化技术完成框架搜索。ModelArts的自动学习可以提供类似体验的功能，并进行模型在共有云的部署。过程流畅，产品特点显著。但是有场景限制，且没有开放相应的API进行二次开发，这不利于用户企业根据自己的业务需求定制自动学习模型，从而实现自动学习的业务场景扩展。

作为对照，百度EasyDL以及可以提供检索后模型架构的，可视化编辑，和存贮。高级用户可以根据规则设定激励政策，设计满足自己特定需求模型设计。

在模型部署上，个人认为头部的企业用户，集中在IOT，汽车，等智能制造行业，他们对基于AMD, INTEL架构的设备有较强的部署需求，能规模化部署产品。而基于公共服务调用企业，一般会直接采购相关按需付费服务，而不会自己去构建。因此如何抓住边缘设备部署问题，使我们整个行业共同面对的问题。

## GPU 训练

目前从用户流程上看，用户可以选择单卡，单机训练模式。目前业界提供两种模式，一种是单机单卡，一种是集群。第一种笔者计算并实践2W元成本的工作站，主机板+2\*Nvidia 16GB计算卡+供电电压+水冷，即可达到近似Tesla V100的性能；第二种，以Testla V100集群，或者K50集群可以提供超高算力的显卡集群十分昂贵，只有少数头部企业才拥有，比通过分布式多卡训练软件支持。第二种是更加，稀缺和珍贵的资源，对某些行业从业人员来说，在云上采购使用才是最划算的做法。我相信这也是ModelArts未来的趋势。

## Notebook

如前所述，Notebook不仅可以运行python，也可以运行c++程序。其已经作为远端虚拟主机的接入口。通过具体的操作测试，我们发现其Build Essential是不完整的，未来希望能够开发sudo权限\(可以使用apt-get等\)。现在我已经在上述项目提供了可替代的解决方案，但是由于磁盘文件并不共享，以及项目不可fork实际上代价巨大。这暴露了：

1. Notebook挂载磁盘是不能够在不同项目共享的，比如构建的`${Build}/local/lib`就不能，在不同项目通过加载系统搜索路径，供项目检索、调用。
2. 现在项目中专业领域的模型，日益更新，以Faster-RCNN, MaskRCNN，目前业界使用的模型和方法，早已和发表之时有较大的差异了。因此各个云团队的企业对接工程师，都在加紧步骤，在自己的机器学习核心框架上开发相关模型，完善方法。
3. 项目本身，可以允许用户以私有项目，或共有项目进行发布。这一点PaddlePaddle团队的AIStuido，走在了前面。区别Google Doc Share模式，AIStuidio引入了Perkle Tree使得项目可，Fork，跟踪，迭代，继承了部分git功能。
4. Notebook在云上，首先云网络带宽，代理，不可能完全如线性运行流畅，因此必要的环境变量的缓存，保护是需要的。比如在不关闭用户主机情况下，用户重新打开nodebook，应当可以找到上一次在内存中驻留的变量。通常我们会给虚拟机一个Timeout，关闭、断开连接一定时间，才会清理内存。这样可以极大提升用户体验。

以`Pytorch Hub`， 为例子，依托在线云生态，用可以可以一键调用模型，并加装所需要数据，和对应架构的预训练模型，完成边缘推理，并以服务方式回传结果，或者接受回调参数。

因此仅仅提供，用户训练主机Notebook还不够。这一点上实际上大有可为，可以以此为契机加强行业合作，构建核心技术壁垒，提供真正的AI即服务。

## 总结

本次使用ModelArts，体验了华为云一部分生态，看着产品落地如此十分振奋。同时谨慎思考，发现还有更多的问题需要去解决。 MLAAS是越来越近了。
