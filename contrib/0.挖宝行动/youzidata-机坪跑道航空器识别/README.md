# 基于keras Faster R-CNN的机坪飞机图像识别

# 应用价值

长期以来，机场塔台指挥以及机坪指挥中，都是通过人眼直接观察以确定飞机在机场或跑道上的位置以进行指挥。然而这存在很多问题，比如发生大雾天等不良天象时难以进行观察并进行有效的指挥，又如仅通过肉眼观察，可能对相对较远的实际的飞机位置缺乏可靠的判断，导致潜在的安全隐患等等。因此，在机场这种广纵深高像素的场景中，急需一种快速有效的识别航空器的手段，以进行航空器位置的分析或者视觉增强。本程序就旨在利用Keras fasterRCNN 实现飞机的在机坪的实时高速识别。本程序所述场景具有较高的商业应用价值。

# 程序介绍

本程序采用yoloV3进行航空器目标识别，参考华为官方目标检测程序。所有程序和数据应部署于华为obs上以供ModelArts使用。本程序的训练和推断都通过ModelArts提供的训练和推断功能加以展示。

# 程序与数据部署

鉴于本程序所用数据较大，为方便实践，本程序的数据和代码打包在一起，存储于百度云上：

链接：https://pan.baidu.com/s/1BmF990Zj7Dyzlh6j3WdFaw 
提取码：is9r 

复制这段内容后打开百度网盘手机App，操作更方便哦
其中程序结构与挖宝行动中提交代码相同。

为确保后续训练配置能够启动成功，obs中推荐文件夹结构如下：
...youzi/   #保存数据与代码的目录
...output/
......|model/ # 用以保存输出模型
...logs/ #保存训练日志

# 训练方法

本程序采用ModelArts的训练作业功能进行训练，创建训练任务后，各个参数可以参考如下图：

![cjob](./md_img/train_config.png)

然后启动训练即可，在P100单显卡下，训练任务时间在230分钟左右，其结果将会保存 obs:/your-buckt/output/model/ 下，包括进行推理工作的全部内容，后续可以利用该文件夹的内容进行推理部署。

# 预测测试

训练完成后，推理可以利用jupyter notebook进行，存储位置建议使用obs，配置可如图：

![juptyer](./md_img/load_model.png)

读取识别图片和训练模型的过程中可以直接读取obs中的内容。

打开src中的 mxnet_object_detection.ipynb 文件，调整obs中bucket的名字，然后按序执行即可看到预测结果

预测结果如下：

![result](./md_img/result01.png)

# 开源协议

本程序遵循Apache 2.0开源协议，程序参考ModelArts-Lab相关内容[https://github.com/huaweicloud/ModelArts-Lab.git]
