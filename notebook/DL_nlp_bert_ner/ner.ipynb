{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 自然语言处理实战——命名实体识别\n",
    "\n",
    "在前面的六期实战营案例中，无论是图像分类还是物体识别，都是对于图像的处理。\n",
    "\n",
    "从本期实战营开始，我们进入到人工智能的另一大重要领域——自然语言处理（NLP，Natural Language Processing）。\n",
    "\n",
    "自然语言处理是人工智能最重要，也是最困难的领域之一，其任务大概可以分为以下几类：\n",
    "\n",
    "- 词法分析：分词、词性标注、拼写校正等\n",
    "\n",
    "\n",
    "- 分类任务：文本分类、情感计算等\n",
    "\n",
    "\n",
    "- 信息抽取：命名实体识别、实体消歧、术语抽取、关系抽取等\n",
    "\n",
    "\n",
    "- 顶层任务：机器翻译、文本摘要、问答系统、阅读理解等\n",
    "\n",
    "在接下来的四期中，我们将接触到四个自然语言处理的任务，同学们有没很期待！\n",
    "\n",
    "首先准备实战环境。\n",
    "\n",
    "### 进入ModelArts\n",
    "\n",
    "点击如下链接：https://www.huaweicloud.com/product/modelarts.html ， 进入ModelArts主页。点击“立即使用”按钮，输入用户名和密码登录，进入ModelArts使用页面。\n",
    "\n",
    "### 创建ModelArts notebook\n",
    "\n",
    "下面，我们在ModelArts中创建一个notebook开发环境，ModelArts notebook提供网页版的Python开发环境，可以方便的编写、运行代码，并查看运行结果。\n",
    "\n",
    "第一步：在ModelArts服务主界面依次点击“开发环境”、“创建”\n",
    "\n",
    "![create_nb_create_button](./img/create_nb_create_button.png)\n",
    "\n",
    "第二步：填写notebook所需的参数：\n",
    "\n",
    "| 参数 | 说明 |\n",
    "| - - - - - | - - - - - |\n",
    "| 计费方式 | 按需计费  |\n",
    "| 名称 | Notebook实例名称 |\n",
    "| 工作环境 | Python3 |\n",
    "| 资源池 | 选择\"公共资源池\"即可 |\n",
    "| 类型 | 选择\"GPU\" |\n",
    "| 规格 | 选择\"8核 &#124; 64GiB &#124; 1*p100\" |\n",
    "| 存储配置 | 选择EVS，磁盘规格5GB |\n",
    "\n",
    "第三步：配置好notebook参数后，点击下一步，进入notebook信息预览。确认无误后，点击“立即创建”\n",
    "\n",
    "![create_nb_creation_summary](./img/create_nb_creation_summary.png)\n",
    "\n",
    "第四步：创建完成后，返回开发环境主界面，等待Notebook创建完毕后，打开Notebook，进行下一步操作。\n",
    "![modelarts_notebook_index](./img/modelarts_notebook_index.png)\n",
    "\n",
    "### 在ModelArts中创建开发环境\n",
    "\n",
    "接下来，我们创建一个实际的开发环境，用于后续的实验步骤。\n",
    "\n",
    "第一步：点击下图所示的“打开”按钮，进入刚刚创建的Notebook\n",
    "![inter_dev_env](img/enter_dev_env.png)\n",
    "\n",
    "第二步：创建一个Python3环境的的Notebook。点击右上角的\"New\"，然后创建TensorFlow 1.13.1开发环境。\n",
    "\n",
    "第三步：点击左上方的文件名\"Untitled\"，并输入一个与本实验相关的名称\n",
    "\n",
    "![notebook_untitled_filename](./img/notebook_untitled_filename.png)\n",
    "![notebook_name_the_ipynb](./img/notebook_name_the_ipynb.png)\n",
    "\n",
    "\n",
    "### 在Notebook中编写并执行代码\n",
    "\n",
    "在Notebook中，我们输入一个简单的打印语句，然后点击上方的运行按钮，可以查看语句执行的结果：\n",
    "![run_helloworld](./img/run_helloworld.png)\n",
    "\n",
    "\n",
    "开发环境准备好啦，接下来可以愉快地写代码啦！\n",
    "\n",
    "\n",
    "### 准备源代码和数据\n",
    "\n",
    "准备案例所需的源代码和数据，相关资源已经保存在 OBS 中，我们通过 ModelArts SDK 将资源下载到本地。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully download file modelarts-labs/notebook/DL_nlp_ner/ner.tar.gz from OBS to local ./ner.tar.gz\n",
      "total 375220\r\n",
      "drwxrwsrwx  4 ma-user ma-group      4096 Sep  6 13:34 .\r\n",
      "drwsrwsr-x 22 ma-user ma-group      4096 Sep  6 13:03 ..\r\n",
      "drwxr-s---  2 ma-user ma-group      4096 Sep  6 13:33 .ipynb_checkpoints\r\n",
      "-rw-r-----  1 ma-user ma-group     45114 Sep  6 13:33 ner.ipynb\r\n",
      "-rw-r-----  1 ma-user ma-group 384157325 Sep  6 13:35 ner.tar.gz\r\n",
      "drwx--S---  2 ma-user ma-group      4096 Sep  6 13:03 .Trash-1000\r\n"
     ]
    }
   ],
   "source": [
    "from modelarts.session import Session\n",
    "session = Session()\n",
    "\n",
    "if session.region_name == 'cn-north-1':\n",
    "    bucket_path = 'modelarts-labs/notebook/DL_nlp_ner/ner.tar.gz'\n",
    "    \n",
    "elif session.region_name == 'cn-north-4':\n",
    "    bucket_path = 'modelarts-labs-bj4/notebook/DL_nlp_ner/ner.tar.gz'\n",
    "else:\n",
    "    print(\"请更换地区到北京一或北京四\")\n",
    "    \n",
    "session.download_data(bucket_path=bucket_path, path='./ner.tar.gz')\n",
    "\n",
    "!ls -la   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "解压从obs下载的压缩包，解压后删除压缩包。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 68\r\n",
      "drwxrwsrwx  5 ma-user ma-group  4096 Sep  6 13:35 .\r\n",
      "drwsrwsr-x 22 ma-user ma-group  4096 Sep  6 13:03 ..\r\n",
      "drwxr-s---  2 ma-user ma-group  4096 Sep  6 13:33 .ipynb_checkpoints\r\n",
      "drwxr-s---  8 ma-user ma-group  4096 Sep  6 00:24 ner\r\n",
      "-rw-r-----  1 ma-user ma-group 45114 Sep  6 13:33 ner.ipynb\r\n",
      "drwx--S---  2 ma-user ma-group  4096 Sep  6 13:03 .Trash-1000\r\n"
     ]
    }
   ],
   "source": [
    "# 解压\n",
    "!tar xf ./ner.tar.gz\n",
    "\n",
    "# 删除\n",
    "!rm ./ner.tar.gz\n",
    "\n",
    "!ls -la    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 命名实体识别简介\n",
    "\n",
    "在自然语言处理任务中，命名实体识别是最为基础的任务之一，为信息抽取、信息检索、机器翻译、问答系统等高阶任务做铺垫。\n",
    "\n",
    "文本中的人名、地名、组织机构名等统一称之为命名实体。\n",
    "\n",
    "在本实战中，选择使用BIO标注：将每个元素标注为“B-X”、“I-X”或者“O”。\n",
    "\n",
    "- B-PER、I-PER 代表人名首字、人名非首字\n",
    "\n",
    "\n",
    "- B-LOC、I-LOC 代表地名首字、地名非首字\n",
    "\n",
    "\n",
    "- B-ORG、I-ORG 代表组织机构名首字、组织机构名非首字\n",
    "\n",
    "\n",
    "- O 代表非命名实体\n",
    "\n",
    "示例如下：\n",
    "\n",
    "![](./img/BIO.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ModelArts 命名实体标注功能\n",
    "\n",
    "本部分将介绍通过 ModelArts 的命名实体标注功能：针对文本中的实体字段进行标注，如“时间”、“地点”等。\n",
    "\n",
    "登录 ModelArts 管理控制台，在左侧菜单栏中选择`数据标注`，进入`数据集`管理页面。\n",
    "\n",
    "点击`创建数据集`，准备用于数据标注的文本数据。\n",
    "\n",
    "![](./img/data_tagging.png)\n",
    "\n",
    "#### 准备未标注数据集\n",
    "\n",
    "首先需要在 OBS 中创建一个数据集，后续的操作如标注数据、数据集发布等，都是基于创建和管理的数据集。\n",
    "\n",
    "OBS 链接在这里：https://www.huaweicloud.com/product/obs0.html\n",
    "\n",
    "数据标注功能需要获取访问 OBS 权限，在未进行委托授权之前，无法使用此功能。需要可以在`数据标注`页面，单击`服务授权`，由具备授权的账号`同意授权`后，即可使用。\n",
    "\n",
    "创建用于存储数据的 OBS 桶及文件夹。本实践中桶名设定为`ner-tagging`，**请用户建立新桶并自定义命名，OBS桶名全局唯一，若创建时桶名冲突，请选择其他不冲突桶名**。\n",
    "\n",
    "桶创建成功后，在桶中创建标注输入和标注输出的文件夹，并将用于标注是文本文件上传到输入文件夹中。\n",
    "\n",
    "文本标注文件的要求为：**文件格式要求 txt 或者 csv，文件大小不超过 8M，以换行符作为分隔符，每行数据代表一个标注对象。**\n",
    "\n",
    "在本实践中使用的示例标注文件`text.txt`可以[点此下载](https://modelarts-labs.obs.cn-north-1.myhuaweicloud.com/notebook/DL_nlp_ner/text.tar.gz)，解压后可上传到输入文件夹中按照本案例步骤使用。\n",
    "\n",
    "在本实践中创建文件夹结构示例如下：\n",
    "\n",
    "```\n",
    "tagging\n",
    "   │\n",
    "   ├─input\n",
    "   │       └─text.txt\n",
    "   └─output\n",
    "```\n",
    "\n",
    "其中\n",
    "\n",
    "- `input`   为命名实体输入文件夹\n",
    "- `text.txt`   为命名实体输入文本文件\n",
    "- `output`   为命名实体输出文件夹\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "创建命名实体任务数据集，如下图所示\n",
    "\n",
    "![](./img/tagging_ner_1.png)\n",
    "\n",
    "注意创建参数\n",
    "\n",
    "- 名称：可自定义数据集名称，本案例中设定为`ner-tagging`\n",
    "- 数据集输入位置：本案例中设定为`/ner-tagging/tagging/input/`\n",
    "- 数据集输出位置：本案例中设定为`/ner-tagging/tagging/output/`\n",
    "- 标注场景：选择`文本`\n",
    "- 标注类型：选择`命名实体`\n",
    "- 添加标签集：可自定义标签名称、个数、颜色。本案例中设定三个分类标签：`人物`标签为蓝色；`时间`标签为绿色；`地点`标签为红色。\n",
    "\n",
    "完成以上设定后，点击右下角`创建`。命名实体数据集创建完成后，系统自动跳转至数据集管理页面。\n",
    "\n",
    "![](./img/tagging_ner_2.png)\n",
    "\n",
    "点击数据集名称，进入标注界面。选择未标注对象，点击标签进行标注，如图所示\n",
    "\n",
    "![](./img/tagging_ner_3.png)\n",
    "\n",
    "选择标注对象：`明天张亮要去体育场打篮球。`\n",
    "\n",
    "- 选取“明天”字段，选择标签`时间`\n",
    "- 选取“张亮”字段，选择标签`人物`\n",
    "- 选取“体育场”字段，选择标签`地点`\n",
    "\n",
    "然后点击下方`保存当前页`进行保存。\n",
    "\n",
    "继续选择其他标注对象，按上述方法进行标注。若需增加标注数据，点击左上角的`添加文件`即可自行增加标注文本。数据全部标注完成后（本样例中仅提供三条命名实体文本），点击`已标注`可查看标注结果。\n",
    "\n",
    "![](./img/tagging_ner_4.png)\n",
    "\n",
    "点击`返回数据集`，可以看到数据集已全部标注成功。\n",
    "\n",
    "![](./img/tagging_ner_5.png)\n",
    "\n",
    "针对刚创建的数据集（未发布前），无数据集版本信息，必须执行发布操作后，才能应用于模型开发或训练。\n",
    "\n",
    "点击`发布`，可以编辑版本名称，本案例中为默认`V001`。\n",
    "\n",
    "![](./img/tagging_ner_6.png)\n",
    "\n",
    "发布成功如图所示。\n",
    "\n",
    "![](./img/tagging_ner_7.png)\n",
    "\n",
    "可以查看数据集版本的 “名称”、 “状态”、 “文件总数”、 “已标注文件个数”，并在左侧的 “演进过程”中查看版本的发布时间。\n",
    "\n",
    "随后可以使用标注成功的数据集，标注结果储存在`output`文件夹中。\n",
    "\n",
    "后续 ModelArts 将会上线**智能标注**功能，相信大家已经体验过第二期实战的图像智能标注，能够快速完成数据标注，节省70%以上的标注时间。智能标注是指基于当前标注阶段的标签及学习训练，选中系统中已有的模型进行智能标注，快速完成剩余数据的标注操作。请持续关注数据标注功能。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据集\n",
    "\n",
    "本实践使用的是《人民日报1998年中文标注语料库》。\n",
    "\n",
    "数据集格式为：每行的第一个是字，第二个是它的标签，字与标签之间使用空格分隔，两句话之间空一行。如下图所示：\n",
    "\n",
    "![](./img/数据集示例.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow==1.11.0 in /home/ma-user/anaconda3/envs/TensorFlow-1.13.1/lib/python3.6/site-packages\n",
      "Requirement already satisfied: absl-py>=0.1.6 in /home/ma-user/anaconda3/envs/TensorFlow-1.13.1/lib/python3.6/site-packages (from tensorflow==1.11.0)\n",
      "Requirement already satisfied: wheel>=0.26 in /home/ma-user/anaconda3/envs/TensorFlow-1.13.1/lib/python3.6/site-packages (from tensorflow==1.11.0)\n",
      "Requirement already satisfied: gast>=0.2.0 in /home/ma-user/anaconda3/envs/TensorFlow-1.13.1/lib/python3.6/site-packages (from tensorflow==1.11.0)\n",
      "Requirement already satisfied: six>=1.10.0 in /home/ma-user/anaconda3/envs/TensorFlow-1.13.1/lib/python3.6/site-packages (from tensorflow==1.11.0)\n",
      "Requirement already satisfied: setuptools<=39.1.0 in /home/ma-user/anaconda3/envs/TensorFlow-1.13.1/lib/python3.6/site-packages (from tensorflow==1.11.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/ma-user/anaconda3/envs/TensorFlow-1.13.1/lib/python3.6/site-packages (from tensorflow==1.11.0)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /home/ma-user/anaconda3/envs/TensorFlow-1.13.1/lib/python3.6/site-packages (from tensorflow==1.11.0)\n",
      "Requirement already satisfied: tensorboard<1.12.0,>=1.11.0 in /home/ma-user/anaconda3/envs/TensorFlow-1.13.1/lib/python3.6/site-packages (from tensorflow==1.11.0)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /home/ma-user/anaconda3/envs/TensorFlow-1.13.1/lib/python3.6/site-packages (from tensorflow==1.11.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.5 in /home/ma-user/anaconda3/envs/TensorFlow-1.13.1/lib/python3.6/site-packages (from tensorflow==1.11.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.3 in /home/ma-user/anaconda3/envs/TensorFlow-1.13.1/lib/python3.6/site-packages (from tensorflow==1.11.0)\n",
      "Requirement already satisfied: protobuf>=3.6.0 in /home/ma-user/anaconda3/envs/TensorFlow-1.13.1/lib/python3.6/site-packages (from tensorflow==1.11.0)\n",
      "Requirement already satisfied: astor>=0.6.0 in /home/ma-user/anaconda3/envs/TensorFlow-1.13.1/lib/python3.6/site-packages (from tensorflow==1.11.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/ma-user/anaconda3/envs/TensorFlow-1.13.1/lib/python3.6/site-packages (from tensorboard<1.12.0,>=1.11.0->tensorflow==1.11.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.10 in /home/ma-user/anaconda3/envs/TensorFlow-1.13.1/lib/python3.6/site-packages (from tensorboard<1.12.0,>=1.11.0->tensorflow==1.11.0)\n",
      "Requirement already satisfied: h5py in /home/ma-user/anaconda3/envs/TensorFlow-1.13.1/lib/python3.6/site-packages (from keras-applications>=1.0.5->tensorflow==1.11.0)\n",
      "\u001b[33mYou are using pip version 9.0.1, however version 19.2.3 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: tensorflow-gpu==1.11.0 in /home/ma-user/anaconda3/envs/TensorFlow-1.13.1/lib/python3.6/site-packages\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /home/ma-user/anaconda3/envs/TensorFlow-1.13.1/lib/python3.6/site-packages (from tensorflow-gpu==1.11.0)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /home/ma-user/anaconda3/envs/TensorFlow-1.13.1/lib/python3.6/site-packages (from tensorflow-gpu==1.11.0)\n",
      "Requirement already satisfied: absl-py>=0.1.6 in /home/ma-user/anaconda3/envs/TensorFlow-1.13.1/lib/python3.6/site-packages (from tensorflow-gpu==1.11.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.5 in /home/ma-user/anaconda3/envs/TensorFlow-1.13.1/lib/python3.6/site-packages (from tensorflow-gpu==1.11.0)\n",
      "Requirement already satisfied: setuptools<=39.1.0 in /home/ma-user/anaconda3/envs/TensorFlow-1.13.1/lib/python3.6/site-packages (from tensorflow-gpu==1.11.0)\n",
      "Requirement already satisfied: tensorboard<1.12.0,>=1.11.0 in /home/ma-user/anaconda3/envs/TensorFlow-1.13.1/lib/python3.6/site-packages (from tensorflow-gpu==1.11.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/ma-user/anaconda3/envs/TensorFlow-1.13.1/lib/python3.6/site-packages (from tensorflow-gpu==1.11.0)\n",
      "Requirement already satisfied: gast>=0.2.0 in /home/ma-user/anaconda3/envs/TensorFlow-1.13.1/lib/python3.6/site-packages (from tensorflow-gpu==1.11.0)\n",
      "Requirement already satisfied: six>=1.10.0 in /home/ma-user/anaconda3/envs/TensorFlow-1.13.1/lib/python3.6/site-packages (from tensorflow-gpu==1.11.0)\n",
      "Requirement already satisfied: astor>=0.6.0 in /home/ma-user/anaconda3/envs/TensorFlow-1.13.1/lib/python3.6/site-packages (from tensorflow-gpu==1.11.0)\n",
      "Requirement already satisfied: wheel>=0.26 in /home/ma-user/anaconda3/envs/TensorFlow-1.13.1/lib/python3.6/site-packages (from tensorflow-gpu==1.11.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.3 in /home/ma-user/anaconda3/envs/TensorFlow-1.13.1/lib/python3.6/site-packages (from tensorflow-gpu==1.11.0)\n",
      "Requirement already satisfied: protobuf>=3.6.0 in /home/ma-user/anaconda3/envs/TensorFlow-1.13.1/lib/python3.6/site-packages (from tensorflow-gpu==1.11.0)\n",
      "Requirement already satisfied: h5py in /home/ma-user/anaconda3/envs/TensorFlow-1.13.1/lib/python3.6/site-packages (from keras-applications>=1.0.5->tensorflow-gpu==1.11.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.10 in /home/ma-user/anaconda3/envs/TensorFlow-1.13.1/lib/python3.6/site-packages (from tensorboard<1.12.0,>=1.11.0->tensorflow-gpu==1.11.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/ma-user/anaconda3/envs/TensorFlow-1.13.1/lib/python3.6/site-packages (from tensorboard<1.12.0,>=1.11.0->tensorflow-gpu==1.11.0)\n",
      "\u001b[33mYou are using pip version 9.0.1, however version 19.2.3 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow==1.11.0\n",
    "\n",
    "!pip install tensorflow-gpu==1.11.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 导入Python库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import codecs\n",
    "import pickle\n",
    "import collections\n",
    "from ner.bert import modeling, optimization, tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 定义路径及参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"./ner/data\"    \n",
    "output_dir = \"./ner/output\"    \n",
    "vocab_file = \"./ner/chinese_L-12_H-768_A-12/vocab.txt\"    \n",
    "data_config_path = \"./ner/chinese_L-12_H-768_A-12/bert_config.json\"    \n",
    "init_checkpoint = \"./ner/chinese_L-12_H-768_A-12/bert_model.ckpt\"    \n",
    "max_seq_length = 128    \n",
    "batch_size = 64    \n",
    "num_train_epochs = 5.0    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 定义processor类获取数据，打印标签"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels: ['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'X', '[CLS]', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "from ner.src.models import InputFeatures, InputExample, DataProcessor, NerProcessor\n",
    "\n",
    "processors = {\"ner\": NerProcessor }\n",
    "processor = processors[\"ner\"](output_dir)\n",
    "\n",
    "label_list = processor.get_labels()\n",
    "print(\"labels:\", label_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 加载预训练参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "显示配置信息:\n",
      "attention_probs_dropout_prob:0.1\n",
      "directionality:bidi\n",
      "hidden_act:gelu\n",
      "hidden_dropout_prob:0.1\n",
      "hidden_size:768\n",
      "initializer_range:0.02\n",
      "intermediate_size:3072\n",
      "max_position_embeddings:512\n",
      "num_attention_heads:12\n",
      "num_hidden_layers:12\n",
      "pooler_fc_size:768\n",
      "pooler_num_attention_heads:12\n",
      "pooler_num_fc_layers:3\n",
      "pooler_size_per_head:128\n",
      "pooler_type:first_token_transform\n",
      "type_vocab_size:2\n",
      "vocab_size:21128\n",
      "num_train_steps:1630\n",
      "num_warmup_steps:163\n",
      "num_train_size:20864\n"
     ]
    }
   ],
   "source": [
    "data_config = json.load(codecs.open(data_config_path))\n",
    "train_examples = processor.get_train_examples(data_dir)    \n",
    "num_train_steps = int(len(train_examples) / batch_size * num_train_epochs)    \n",
    "num_warmup_steps = int(num_train_steps * 0.1)   \n",
    "data_config['num_train_steps'] = num_train_steps\n",
    "data_config['num_warmup_steps'] = num_warmup_steps\n",
    "data_config['num_train_size'] = len(train_examples)\n",
    "\n",
    "print(\"显示配置信息:\")\n",
    "for key,value in data_config.items():\n",
    "    print('{key}:{value}'.format(key = key, value = value))\n",
    "\n",
    "bert_config = modeling.BertConfig.from_json_file(data_config_path)\n",
    "tokenizer = tokenization.FullTokenizer(vocab_file=vocab_file, do_lower_case=True)\n",
    "\n",
    "#tf.estimator运行参数\n",
    "run_config = tf.estimator.RunConfig(\n",
    "    model_dir=output_dir,\n",
    "    save_summary_steps=1000,\n",
    "    save_checkpoints_steps=1000,\n",
    "    session_config=tf.ConfigProto(\n",
    "        log_device_placement=False,\n",
    "        inter_op_parallelism_threads=0,\n",
    "        intra_op_parallelism_threads=0,\n",
    "        allow_soft_placement=True\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 读取数据，获取句向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 0 of 20864\n",
      "INFO:tensorflow:Writing example 5000 of 20864\n",
      "INFO:tensorflow:Writing example 10000 of 20864\n",
      "INFO:tensorflow:Writing example 15000 of 20864\n",
      "INFO:tensorflow:Writing example 20000 of 20864\n"
     ]
    }
   ],
   "source": [
    "def convert_single_example(ex_index, example, label_list, max_seq_length, \n",
    "                           tokenizer, output_dir, mode):\n",
    "    label_map = {}\n",
    "    for (i, label) in enumerate(label_list, 1):\n",
    "        label_map[label] = i\n",
    "    if not os.path.exists(os.path.join(output_dir, 'label2id.pkl')):\n",
    "        with codecs.open(os.path.join(output_dir, 'label2id.pkl'), 'wb') as w:\n",
    "            pickle.dump(label_map, w)\n",
    "\n",
    "    textlist = example.text.split(' ')\n",
    "    labellist = example.label.split(' ')\n",
    "    tokens = []\n",
    "    labels = []\n",
    "    for i, word in enumerate(textlist):\n",
    "        token = tokenizer.tokenize(word)\n",
    "        tokens.extend(token)\n",
    "        label_1 = labellist[i]\n",
    "        for m in range(len(token)):\n",
    "            if m == 0:\n",
    "                labels.append(label_1)\n",
    "            else:  \n",
    "                labels.append(\"X\")\n",
    "    if len(tokens) >= max_seq_length - 1:\n",
    "        tokens = tokens[0:(max_seq_length - 2)]\n",
    "        labels = labels[0:(max_seq_length - 2)]\n",
    "    ntokens = []\n",
    "    segment_ids = []\n",
    "    label_ids = []\n",
    "    ntokens.append(\"[CLS]\")  # 句子开始设置 [CLS] 标志\n",
    "    segment_ids.append(0)\n",
    "    label_ids.append(label_map[\"[CLS]\"])  \n",
    "    for i, token in enumerate(tokens):\n",
    "        ntokens.append(token)\n",
    "        segment_ids.append(0)\n",
    "        label_ids.append(label_map[labels[i]])\n",
    "    ntokens.append(\"[SEP]\")  # 句尾添加 [SEP] 标志\n",
    "    segment_ids.append(0)\n",
    "    label_ids.append(label_map[\"[SEP]\"])\n",
    "    input_ids = tokenizer.convert_tokens_to_ids(ntokens)  \n",
    "    input_mask = [1] * len(input_ids)\n",
    "\n",
    "    while len(input_ids) < max_seq_length:\n",
    "        input_ids.append(0)\n",
    "        input_mask.append(0)\n",
    "        segment_ids.append(0)\n",
    "        label_ids.append(0)\n",
    "        ntokens.append(\"**NULL**\")\n",
    "\n",
    "    assert len(input_ids) == max_seq_length\n",
    "    assert len(input_mask) == max_seq_length\n",
    "    assert len(segment_ids) == max_seq_length\n",
    "    assert len(label_ids) == max_seq_length\n",
    "\n",
    "    feature = InputFeatures(\n",
    "        input_ids=input_ids,\n",
    "        input_mask=input_mask,\n",
    "        segment_ids=segment_ids,\n",
    "        label_ids=label_ids,\n",
    "    )\n",
    "   \n",
    "    return feature\n",
    "\n",
    "def filed_based_convert_examples_to_features(\n",
    "        examples, label_list, max_seq_length, tokenizer, output_file, mode=None):\n",
    "    writer = tf.python_io.TFRecordWriter(output_file)\n",
    "    for (ex_index, example) in enumerate(examples):\n",
    "        if ex_index % 5000 == 0:\n",
    "            tf.logging.info(\"Writing example %d of %d\" % (ex_index, len(examples)))\n",
    "        feature = convert_single_example(ex_index, example, label_list, max_seq_length, tokenizer, output_dir, mode)\n",
    "\n",
    "        def create_int_feature(values):\n",
    "            f = tf.train.Feature(int64_list=tf.train.Int64List(value=list(values)))\n",
    "            return f\n",
    "\n",
    "        features = collections.OrderedDict()\n",
    "        features[\"input_ids\"] = create_int_feature(feature.input_ids)\n",
    "        features[\"input_mask\"] = create_int_feature(feature.input_mask)\n",
    "        features[\"segment_ids\"] = create_int_feature(feature.segment_ids)\n",
    "        features[\"label_ids\"] = create_int_feature(feature.label_ids)\n",
    "        tf_example = tf.train.Example(features=tf.train.Features(feature=features))\n",
    "        writer.write(tf_example.SerializeToString())\n",
    "\n",
    "train_file = os.path.join(output_dir, \"train.tf_record\")\n",
    "\n",
    "#将训练集中字符转化为features作为训练的输入\n",
    "filed_based_convert_examples_to_features(\n",
    "            train_examples, label_list, max_seq_length, tokenizer, output_file=train_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 引入 BiLSTM+CRF 层，作为下游模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 5e-5 \n",
    "dropout_rate = 1.0   \n",
    "lstm_size=1    \n",
    "cell='lstm'\n",
    "num_layers=1\n",
    "\n",
    "from ner.src.models import BLSTM_CRF\n",
    "from tensorflow.contrib.layers.python.layers import initializers\n",
    "\n",
    "def create_model(bert_config, is_training, input_ids, input_mask,\n",
    "                 segment_ids, labels, num_labels, use_one_hot_embeddings,\n",
    "                 dropout_rate=dropout_rate, lstm_size=1, cell='lstm', num_layers=1):\n",
    "    model = modeling.BertModel(\n",
    "        config=bert_config,\n",
    "        is_training=is_training,\n",
    "        input_ids=input_ids,\n",
    "        input_mask=input_mask,\n",
    "        token_type_ids=segment_ids,\n",
    "        use_one_hot_embeddings=use_one_hot_embeddings\n",
    "    )\n",
    "    embedding = model.get_sequence_output()\n",
    "    max_seq_length = embedding.shape[1].value\n",
    "    used = tf.sign(tf.abs(input_ids))\n",
    "    lengths = tf.reduce_sum(used, reduction_indices=1)  \n",
    "    blstm_crf = BLSTM_CRF(embedded_chars=embedding, hidden_unit=1, cell_type='lstm', num_layers=1,\n",
    "                          dropout_rate=dropout_rate, initializers=initializers, num_labels=num_labels,\n",
    "                          seq_length=max_seq_length, labels=labels, lengths=lengths, is_training=is_training)\n",
    "    rst = blstm_crf.add_blstm_crf_layer(crf_only=True)\n",
    "    return rst\n",
    "\n",
    "def model_fn_builder(bert_config, num_labels, init_checkpoint, learning_rate,\n",
    "                     num_train_steps, num_warmup_steps,use_one_hot_embeddings=False):\n",
    "    #构建模型\n",
    "    def model_fn(features, labels, mode, params):\n",
    "        tf.logging.info(\"*** Features ***\")\n",
    "        for name in sorted(features.keys()):\n",
    "            tf.logging.info(\"  name = %s, shape = %s\" % (name, features[name].shape))\n",
    "        input_ids = features[\"input_ids\"]\n",
    "        input_mask = features[\"input_mask\"]\n",
    "        segment_ids = features[\"segment_ids\"]\n",
    "        label_ids = features[\"label_ids\"]\n",
    "\n",
    "        print('shape of input_ids', input_ids.shape)\n",
    "        is_training = (mode == tf.estimator.ModeKeys.TRAIN)\n",
    "\n",
    "        total_loss, logits, trans, pred_ids = create_model(\n",
    "            bert_config, is_training, input_ids, input_mask, segment_ids, label_ids,\n",
    "            num_labels, False, dropout_rate, lstm_size, cell, num_layers)\n",
    "\n",
    "        tvars = tf.trainable_variables()\n",
    "\n",
    "        if init_checkpoint:\n",
    "            (assignment_map, initialized_variable_names) = \\\n",
    "                 modeling.get_assignment_map_from_checkpoint(tvars, init_checkpoint)\n",
    "            tf.train.init_from_checkpoint(init_checkpoint, assignment_map)\n",
    "        \n",
    "        output_spec = None\n",
    "        if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "            train_op = optimization.create_optimizer(\n",
    "                 total_loss, learning_rate, num_train_steps, num_warmup_steps, False)\n",
    "            hook_dict = {}\n",
    "            hook_dict['loss'] = total_loss\n",
    "            hook_dict['global_steps'] = tf.train.get_or_create_global_step()\n",
    "            logging_hook = tf.train.LoggingTensorHook(\n",
    "                hook_dict, every_n_iter=100)\n",
    "\n",
    "            output_spec = tf.estimator.EstimatorSpec(\n",
    "                mode=mode,\n",
    "                loss=total_loss,\n",
    "                train_op=train_op,\n",
    "                training_hooks=[logging_hook])\n",
    "\n",
    "        elif mode == tf.estimator.ModeKeys.EVAL:\n",
    "            def metric_fn(label_ids, pred_ids):\n",
    "\n",
    "                return {\n",
    "                    \"eval_loss\": tf.metrics.mean_squared_error(labels=label_ids, predictions=pred_ids),   }\n",
    "            \n",
    "            eval_metrics = metric_fn(label_ids, pred_ids)\n",
    "            output_spec = tf.estimator.EstimatorSpec(\n",
    "                mode=mode,\n",
    "                loss=total_loss,\n",
    "                eval_metric_ops=eval_metrics\n",
    "            )\n",
    "        else:\n",
    "            output_spec = tf.estimator.EstimatorSpec(\n",
    "                mode=mode,\n",
    "                predictions=pred_ids\n",
    "            )\n",
    "        return output_spec\n",
    "\n",
    "    return model_fn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 创建模型，开始训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:***** Running training *****\n",
      "INFO:tensorflow:  Num examples = 20864\n",
      "INFO:tensorflow:  Batch size = 64\n",
      "INFO:tensorflow:  Num steps = 1630\n",
      "INFO:tensorflow:Using config: {'_model_dir': './ner/output', '_tf_random_seed': None, '_save_summary_steps': 1000, '_save_checkpoints_steps': 1000, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fca68ba6748>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:*** Features ***\n",
      "INFO:tensorflow:  name = input_ids, shape = (32, 128)\n",
      "INFO:tensorflow:  name = input_mask, shape = (32, 128)\n",
      "INFO:tensorflow:  name = label_ids, shape = (32, 128)\n",
      "INFO:tensorflow:  name = segment_ids, shape = (32, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of input_ids (32, 128)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into ./ner/output/model.ckpt.\n",
      "INFO:tensorflow:loss = 159.27417, step = 0\n",
      "INFO:tensorflow:global_steps = 0, loss = 159.27417\n",
      "INFO:tensorflow:global_step/sec: 1.43142\n",
      "INFO:tensorflow:loss = 52.92234, step = 100 (69.862 sec)\n",
      "INFO:tensorflow:global_steps = 100, loss = 52.92234 (69.862 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.81746\n",
      "INFO:tensorflow:loss = 45.81129, step = 200 (55.022 sec)\n",
      "INFO:tensorflow:global_steps = 200, loss = 45.81129 (55.022 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.82186\n",
      "INFO:tensorflow:loss = 48.826424, step = 300 (54.890 sec)\n",
      "INFO:tensorflow:global_steps = 300, loss = 48.826424 (54.890 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.82109\n",
      "INFO:tensorflow:loss = 44.61993, step = 400 (54.910 sec)\n",
      "INFO:tensorflow:global_steps = 400, loss = 44.61993 (54.911 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.82003\n",
      "INFO:tensorflow:loss = 44.479523, step = 500 (54.944 sec)\n",
      "INFO:tensorflow:global_steps = 500, loss = 44.479523 (54.944 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.81887\n",
      "INFO:tensorflow:loss = 43.29698, step = 600 (54.979 sec)\n",
      "INFO:tensorflow:global_steps = 600, loss = 43.29698 (54.981 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.82034\n",
      "INFO:tensorflow:loss = 52.886993, step = 700 (54.938 sec)\n",
      "INFO:tensorflow:global_steps = 700, loss = 52.886993 (54.936 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.81812\n",
      "INFO:tensorflow:loss = 46.30081, step = 800 (54.999 sec)\n",
      "INFO:tensorflow:global_steps = 800, loss = 46.30081 (54.999 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.824\n",
      "INFO:tensorflow:loss = 47.800972, step = 900 (54.824 sec)\n",
      "INFO:tensorflow:global_steps = 900, loss = 47.800972 (54.824 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into ./ner/output/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.53438\n",
      "INFO:tensorflow:loss = 45.00616, step = 1000 (65.173 sec)\n",
      "INFO:tensorflow:global_steps = 1000, loss = 45.00616 (65.173 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.81754\n",
      "INFO:tensorflow:loss = 41.210243, step = 1100 (55.020 sec)\n",
      "INFO:tensorflow:global_steps = 1100, loss = 41.210243 (55.020 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.81626\n",
      "INFO:tensorflow:loss = 48.78985, step = 1200 (55.058 sec)\n",
      "INFO:tensorflow:global_steps = 1200, loss = 48.78985 (55.058 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.81829\n",
      "INFO:tensorflow:loss = 48.236824, step = 1300 (54.997 sec)\n",
      "INFO:tensorflow:global_steps = 1300, loss = 48.236824 (55.000 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.81966\n",
      "INFO:tensorflow:loss = 49.241657, step = 1400 (54.956 sec)\n",
      "INFO:tensorflow:global_steps = 1400, loss = 49.241657 (54.952 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.81475\n",
      "INFO:tensorflow:loss = 49.225563, step = 1500 (55.104 sec)\n",
      "INFO:tensorflow:global_steps = 1500, loss = 49.225563 (55.104 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.81869\n",
      "INFO:tensorflow:loss = 43.25946, step = 1600 (54.988 sec)\n",
      "INFO:tensorflow:global_steps = 1600, loss = 43.25946 (54.988 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1630 into ./ner/output/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 50.242386.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.estimator.Estimator at 0x7fca68ad65c0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_fn = model_fn_builder(\n",
    "        bert_config=bert_config,\n",
    "        num_labels=len(label_list) + 1,\n",
    "        init_checkpoint=init_checkpoint,\n",
    "        learning_rate=learning_rate,\n",
    "        num_train_steps=num_train_steps,\n",
    "        num_warmup_steps=num_warmup_steps,\n",
    "        use_one_hot_embeddings=False)\n",
    "\n",
    "def file_based_input_fn_builder(input_file, seq_length, is_training, drop_remainder):\n",
    "    name_to_features = {\n",
    "        \"input_ids\": tf.FixedLenFeature([seq_length], tf.int64),\n",
    "        \"input_mask\": tf.FixedLenFeature([seq_length], tf.int64),\n",
    "        \"segment_ids\": tf.FixedLenFeature([seq_length], tf.int64),\n",
    "        \"label_ids\": tf.FixedLenFeature([seq_length], tf.int64),\n",
    "    }\n",
    "\n",
    "    def _decode_record(record, name_to_features):\n",
    "        example = tf.parse_single_example(record, name_to_features)\n",
    "        for name in list(example.keys()):\n",
    "            t = example[name]\n",
    "            if t.dtype == tf.int64:\n",
    "                t = tf.to_int32(t)\n",
    "            example[name] = t\n",
    "        return example\n",
    "\n",
    "    def input_fn(params):\n",
    "        params[\"batch_size\"] = 32\n",
    "        batch_size = params[\"batch_size\"]\n",
    "        d = tf.data.TFRecordDataset(input_file)\n",
    "        if is_training:\n",
    "            d = d.repeat()\n",
    "            d = d.shuffle(buffer_size=300)\n",
    "        d = d.apply(tf.contrib.data.map_and_batch(\n",
    "            lambda record: _decode_record(record, name_to_features),\n",
    "            batch_size=batch_size,\n",
    "            drop_remainder=drop_remainder\n",
    "        ))\n",
    "        return d\n",
    "\n",
    "    return input_fn\n",
    "\n",
    "#训练输入\n",
    "train_input_fn = file_based_input_fn_builder(\n",
    "            input_file=train_file,\n",
    "            seq_length=max_seq_length,\n",
    "            is_training=True,\n",
    "            drop_remainder=True)\n",
    "\n",
    "num_train_size = len(train_examples)\n",
    "\n",
    "tf.logging.info(\"***** Running training *****\")\n",
    "tf.logging.info(\"  Num examples = %d\", num_train_size)\n",
    "tf.logging.info(\"  Batch size = %d\", batch_size)\n",
    "tf.logging.info(\"  Num steps = %d\", num_train_steps)\n",
    "\n",
    "#模型预测estimator\n",
    "estimator = tf.estimator.Estimator(\n",
    "        model_fn=model_fn,\n",
    "        config=run_config,\n",
    "        params={\n",
    "        'batch_size':batch_size\n",
    "    })\n",
    "\n",
    "estimator.train(input_fn=train_input_fn, max_steps=num_train_steps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 在验证集上验证模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 0 of 4631\n",
      "INFO:tensorflow:***** Running evaluation *****\n",
      "INFO:tensorflow:  Num examples = 4631\n",
      "INFO:tensorflow:  Batch size = 64\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:*** Features ***\n",
      "INFO:tensorflow:  name = input_ids, shape = (?, 128)\n",
      "INFO:tensorflow:  name = input_mask, shape = (?, 128)\n",
      "INFO:tensorflow:  name = label_ids, shape = (?, 128)\n",
      "INFO:tensorflow:  name = segment_ids, shape = (?, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of input_ids (?, 128)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-09-06-05:53:54\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./ner/output/model.ckpt-1630\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-09-06-05:54:35\n",
      "INFO:tensorflow:Saving dict for global step 1630: eval_loss = 0.042222254, global_step = 1630, loss = 35.88692\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1630: ./ner/output/model.ckpt-1630\n",
      "INFO:tensorflow:***** Eval results *****\n",
      "INFO:tensorflow:  eval_loss = 0.042222254\n",
      "INFO:tensorflow:  global_step = 1630\n",
      "INFO:tensorflow:  loss = 35.88692\n"
     ]
    }
   ],
   "source": [
    "eval_examples = processor.get_dev_examples(data_dir)\n",
    "eval_file = os.path.join(output_dir, \"eval.tf_record\")\n",
    "filed_based_convert_examples_to_features(\n",
    "                eval_examples, label_list, max_seq_length, tokenizer, eval_file)\n",
    "data_config['eval.tf_record_path'] = eval_file\n",
    "data_config['num_eval_size'] = len(eval_examples)\n",
    "num_eval_size = data_config.get('num_eval_size', 0)\n",
    "\n",
    "tf.logging.info(\"***** Running evaluation *****\")\n",
    "tf.logging.info(\"  Num examples = %d\", num_eval_size)\n",
    "tf.logging.info(\"  Batch size = %d\", batch_size)\n",
    "\n",
    "eval_steps = None\n",
    "eval_drop_remainder = False\n",
    "eval_input_fn = file_based_input_fn_builder(\n",
    "            input_file=eval_file,\n",
    "            seq_length=max_seq_length,\n",
    "            is_training=False,\n",
    "            drop_remainder=eval_drop_remainder)\n",
    "\n",
    "result = estimator.evaluate(input_fn=eval_input_fn, steps=eval_steps)\n",
    "output_eval_file = os.path.join(output_dir, \"eval_results.txt\")\n",
    "with codecs.open(output_eval_file, \"w\", encoding='utf-8') as writer:\n",
    "    tf.logging.info(\"***** Eval results *****\")\n",
    "    for key in sorted(result.keys()):\n",
    "        tf.logging.info(\"  %s = %s\", key, str(result[key]))\n",
    "        writer.write(\"%s = %s\\n\" % (key, str(result[key])))\n",
    "\n",
    "if not os.path.exists(data_config_path):\n",
    "    with codecs.open(data_config_path, 'a', encoding='utf-8') as fd:\n",
    "        json.dump(data_config, fd)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 在测试集上进行测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 0 of 68\n",
      "INFO:tensorflow:***** Running prediction*****\n",
      "INFO:tensorflow:  Num examples = 68\n",
      "INFO:tensorflow:  Batch size = 64\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:*** Features ***\n",
      "INFO:tensorflow:  name = input_ids, shape = (?, 128)\n",
      "INFO:tensorflow:  name = input_mask, shape = (?, 128)\n",
      "INFO:tensorflow:  name = label_ids, shape = (?, 128)\n",
      "INFO:tensorflow:  name = segment_ids, shape = (?, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of input_ids (?, 128)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-09-06-05:55:20\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./ner/output/model.ckpt-1630\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-09-06-05:55:24\n",
      "INFO:tensorflow:Saving dict for global step 1630: eval_loss = 0.017003676, global_step = 1630, loss = 34.176826\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1630: ./ner/output/model.ckpt-1630\n",
      "INFO:tensorflow:***** Predict results *****\n",
      "INFO:tensorflow:  eval_loss = 0.017003676\n",
      "INFO:tensorflow:  global_step = 1630\n",
      "INFO:tensorflow:  loss = 34.176826\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:*** Features ***\n",
      "INFO:tensorflow:  name = input_ids, shape = (?, 128)\n",
      "INFO:tensorflow:  name = input_mask, shape = (?, 128)\n",
      "INFO:tensorflow:  name = label_ids, shape = (?, 128)\n",
      "INFO:tensorflow:  name = segment_ids, shape = (?, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of input_ids (?, 128)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./ner/output/model.ckpt-1630\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed 2270 tokens with 78 phrases; found: 82 phrases; correct: 76.\n",
      "\n",
      "accuracy:  99.56%; precision:  92.68%; recall:  97.44%; FB1:  95.00\n",
      "\n",
      "              LOC: precision:  97.83%; recall: 100.00%; FB1:  98.90  46\n",
      "\n",
      "              ORG: precision:  66.67%; recall: 100.00%; FB1:  80.00  12\n",
      "\n",
      "              PER: precision:  95.83%; recall:  92.00%; FB1:  93.88  24\n",
      "\n"
     ]
    }
   ],
   "source": [
    "token_path = os.path.join(output_dir, \"token_test.txt\")\n",
    "if os.path.exists(token_path):\n",
    "    os.remove(token_path)\n",
    "\n",
    "with codecs.open(os.path.join(output_dir, 'label2id.pkl'), 'rb') as rf:\n",
    "    label2id = pickle.load(rf)\n",
    "    id2label = {value: key for key, value in label2id.items()}\n",
    "\n",
    "predict_examples = processor.get_test_examples(data_dir)\n",
    "predict_file = os.path.join(output_dir, \"predict.tf_record\")\n",
    "filed_based_convert_examples_to_features(predict_examples, label_list,\n",
    "                                                 max_seq_length, tokenizer,\n",
    "                                                 predict_file, mode=\"test\")\n",
    "\n",
    "tf.logging.info(\"***** Running prediction*****\")\n",
    "tf.logging.info(\"  Num examples = %d\", len(predict_examples))\n",
    "tf.logging.info(\"  Batch size = %d\", batch_size)\n",
    "    \n",
    "predict_drop_remainder = False\n",
    "predict_input_fn = file_based_input_fn_builder(\n",
    "            input_file=predict_file,\n",
    "            seq_length=max_seq_length,\n",
    "            is_training=False,\n",
    "            drop_remainder=predict_drop_remainder)\n",
    "\n",
    "predicted_result = estimator.evaluate(input_fn=predict_input_fn)\n",
    "output_eval_file = os.path.join(output_dir, \"predicted_results.txt\")\n",
    "with codecs.open(output_eval_file, \"w\", encoding='utf-8') as writer:\n",
    "    tf.logging.info(\"***** Predict results *****\")\n",
    "    for key in sorted(predicted_result.keys()):\n",
    "        tf.logging.info(\"  %s = %s\", key, str(predicted_result[key]))\n",
    "        writer.write(\"%s = %s\\n\" % (key, str(predicted_result[key])))\n",
    "\n",
    "result = estimator.predict(input_fn=predict_input_fn)\n",
    "output_predict_file = os.path.join(output_dir, \"label_test.txt\")\n",
    "\n",
    "def result_to_pair(writer):\n",
    "    for predict_line, prediction in zip(predict_examples, result):\n",
    "        idx = 0\n",
    "        line = ''\n",
    "        line_token = str(predict_line.text).split(' ')\n",
    "        label_token = str(predict_line.label).split(' ')\n",
    "        if len(line_token) != len(label_token):\n",
    "            tf.logging.info(predict_line.text)\n",
    "            tf.logging.info(predict_line.label)\n",
    "        for id in prediction:\n",
    "            if id == 0:\n",
    "                continue\n",
    "            curr_labels = id2label[id]\n",
    "            if curr_labels in ['[CLS]', '[SEP]']:\n",
    "                continue\n",
    "            try:\n",
    "                line += line_token[idx] + ' ' + label_token[idx] + ' ' + curr_labels + '\\n'\n",
    "            except Exception as e:\n",
    "                tf.logging.info(e)\n",
    "                tf.logging.info(predict_line.text)\n",
    "                tf.logging.info(predict_line.label)\n",
    "                line = ''\n",
    "                break\n",
    "            idx += 1\n",
    "        writer.write(line + '\\n')\n",
    "            \n",
    "from ner.src.conlleval import return_report\n",
    "\n",
    "with codecs.open(output_predict_file, 'w', encoding='utf-8') as writer:\n",
    "    result_to_pair(writer)\n",
    "eval_result = return_report(output_predict_file)\n",
    "for line in eval_result:\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 在线命名实体识别\n",
    "\n",
    "由以上训练得到模型进行在线测试，可以任意输入句子，进行命名实体识别。\n",
    "\n",
    "输入“再见”，结束在线命名实体识别。\n",
    "\n",
    "<span style=\"color:red\">若下述程序未执行成功，则表示训练完成后，GPU显存还在占用，需要restart kernel，然后执行 %run 命令。</span>\n",
    "\n",
    "释放资源具体流程为：菜单 > Kernel > Restart  \n",
    "\n",
    "![释放资源](./img/释放资源.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint path:./ner/output/checkpoint\n",
      "going to restore checkpoint\n",
      "INFO:tensorflow:Restoring parameters from ./ner/output/model.ckpt-1630\n",
      "{1: 'O', 2: 'B-PER', 3: 'I-PER', 4: 'B-ORG', 5: 'I-ORG', 6: 'B-LOC', 7: 'I-LOC', 8: 'X', 9: '[CLS]', 10: '[SEP]'}\n",
      "输入句子:\n",
      "中国男篮与委内瑞拉队在北京五棵松体育馆展开小组赛最后一场比赛的争夺，赵继伟12分4助攻3抢断、易建联11分8篮板、周琦8分7篮板2盖帽。\n",
      "[['B-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'O', 'B-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'O', 'B-LOC', 'I-LOC', 'B-LOC', 'I-LOC', 'I-LOC', 'I-LOC', 'I-LOC', 'I-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'I-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'I-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']]\n",
      "LOC, 北京, 五棵松体育馆\n",
      "PER, 赵继伟, 易建联, 周琦\n",
      "ORG, 中国男篮, 委内瑞拉队\n",
      "time used: 0.908481 sec\n",
      "输入句子:\n",
      "周杰伦（Jay Chou），1979年1月18日出生于台湾省新北市，毕业于淡江中学，中国台湾流行乐男歌手。\n",
      "[['B-PER', 'I-PER', 'I-PER', 'O', 'B-PER', 'I-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'I-LOC', 'I-LOC', 'B-LOC', 'I-LOC', 'I-LOC', 'O', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'O', 'B-LOC', 'I-LOC', 'B-LOC', 'I-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O']]\n",
      "LOC, 台湾省, 新北市, 中国, 台湾\n",
      "PER, 周杰伦, jaycho##u\n",
      "ORG, 淡江中学\n",
      "time used: 0.058148 sec\n",
      "输入句子:\n",
      "马云，1964年9月10日生于浙江省杭州市，1988年毕业于杭州师范学院外语系，同年担任杭州电子工业学院英文及国际贸易教师。\n",
      "[['B-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'I-LOC', 'I-LOC', 'B-LOC', 'I-LOC', 'I-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']]\n",
      "LOC, 浙江省, 杭州市\n",
      "PER, 马云\n",
      "ORG, 杭州师范学院外语系, 杭州电子工业学院\n",
      "time used: 0.065471 sec\n",
      "输入句子:\n",
      "再见\n",
      "\n",
      "再见\n"
     ]
    }
   ],
   "source": [
    "%run ner/src/terminal_predict.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
