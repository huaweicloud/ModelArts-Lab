{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modelarts.session import Session\n",
    "session = Session()\n",
    "\n",
    "session.download_data(\n",
    "    bucket_path=\"modelarts-labs/notebook/DL_image_recognition/image_recognition.tar.gz\",\n",
    "    path=\"./image_recognition.tar.gz\")\n",
    "\n",
    "# 使用tar命令解压资源包\n",
    "!tar xf ./image_recognition.tar.gz\n",
    "\n",
    "# 清理压缩包\n",
    "!rm -f ./image_recognition.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.download_data(\n",
    "    bucket_path=\"ai-course-ansel/efficientnet-b0.tar.gz\",\n",
    "    path=\"./efficientnet-b0.tar.gz\")\n",
    "\n",
    "# 使用tar命令解压资源包\n",
    "!tar xf ./efficientnet-b0.tar.gz\n",
    "\n",
    "# 清理压缩包\n",
    "!rm -f ./efficientnet-b0.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data\t\t\t\t\tlost+found\r\n",
      "dog_and_cat_efficientnetb0-Copy1.ipynb\tmain.py\r\n",
      "efficientnet-b0\t\t\t\tpreprocessing.py\r\n",
      "efficientnet_builder.py\t\t\t__pycache__\r\n",
      "efficientnet_model.py\t\t\tREADME.md\r\n",
      "eval_ckpt_example.ipynb\t\t\tupgrade tensorflow 1.14.0.ipynb\r\n",
      "eval_ckpt_main.py\t\t\tutils.py\r\n",
      "imagenet_input.py\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.14.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import tensorflow as tf\n",
    "#tf.enable_eager_execution()\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = './data/'\n",
    "model_name = model_name = 'efficientnet-b0'\n",
    "ckpt_dir = './efficientnet-b0/'\n",
    "export_ckpt_dir = None\n",
    "BATCH_SIZE = 32\n",
    "#MEAN_RGB = [0.485 * 255, 0.456 * 255, 0.406 * 255]\n",
    "#STDDEV_RGB = [0.229 * 255, 0.224 * 255, 0.225 * 255]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_image_paths = [DATA_DIR+i for i in os.listdir(DATA_DIR)]\n",
    "random.shuffle(all_image_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_image_labels=[]\n",
    "for i in all_image_paths:\n",
    "    if 'dog' in i:\n",
    "        all_image_labels.append(1)\n",
    "    else:\n",
    "        all_image_labels.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image):\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.resize(image, [224, 224])\n",
    "    #image -= tf.constant(MEAN_RGB, shape=[1, 1, 3], dtype=image.dtype)\n",
    "    #image /= tf.constant(STDDEV_RGB, shape=[1, 1, 3], dtype=image.dtype)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_image(path):\n",
    "    image = tf.io.read_file(path)\n",
    "    return preprocess_image(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_paths, test_paths, train_labels, test_labels = train_test_split(all_image_paths, all_image_labels, test_size=0.2, random_state=10)\n",
    "tra_paths,val_paths,tra_labels,val_labels = train_test_split(train_paths,train_labels,test_size=0.2,random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataset(images,labels):\n",
    "    ds = tf.data.Dataset.from_tensor_slices((tra_paths, tra_labels))\n",
    "    # The tuples are unpacked into the positional arguments of the mapped function\n",
    "    def load_and_preprocess_from_path_label(path, label):\n",
    "        return load_and_preprocess_image(path), label\n",
    "    image_label_ds = ds.map(load_and_preprocess_from_path_label)\n",
    "    ds = image_label_ds.apply(tf.data.experimental.shuffle_and_repeat(buffer_size=len(labels)))\n",
    "    ds = ds.batch(BATCH_SIZE).prefetch(buffer_size=AUTOTUNE)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0711 13:13:23.924025 140484842403584 deprecation.py:323] From <ipython-input-10-07c1cf0db198>:7: shuffle_and_repeat (from tensorflow.python.data.experimental.ops.shuffle_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.shuffle(buffer_size, seed)` followed by `tf.data.Dataset.repeat(count)`. Static tf.data optimizations will take care of using the fused implementation.\n"
     ]
    }
   ],
   "source": [
    "train_batches = build_dataset(tra_paths,tra_labels)\n",
    "test_batches = build_dataset(test_paths,test_labels)\n",
    "val_batches = build_dataset(val_paths,val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#image_batch, label_batch = next(iter(ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0711 13:13:30.855360 140484842403584 deprecation_wrapper.py:119] From /home/jovyan/work/utils.py:86: The name tf.layers.BatchNormalization is deprecated. Please use tf.compat.v1.layers.BatchNormalization instead.\n",
      "\n",
      "W0711 13:13:30.856772 140484842403584 deprecation_wrapper.py:119] From /home/jovyan/work/utils.py:200: The name tf.layers.Layer is deprecated. Please use tf.compat.v1.layers.Layer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import efficientnet_model\n",
    "import efficientnet_builder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0711 13:13:31.078946 140484842403584 deprecation_wrapper.py:119] From /home/jovyan/work/efficientnet_builder.py:157: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
      "\n",
      "W0711 13:13:31.088542 140484842403584 deprecation.py:506] From /opt/conda/envs/python36_tf/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0711 13:13:31.090062 140484842403584 deprecation_wrapper.py:119] From /home/jovyan/work/efficientnet_model.py:201: The name tf.layers.Conv2D is deprecated. Please use tf.compat.v1.layers.Conv2D instead.\n",
      "\n",
      "W0711 13:13:31.119100 140484842403584 deprecation_wrapper.py:119] From /home/jovyan/work/efficientnet_model.py:372: The name tf.layers.Dense is deprecated. Please use tf.compat.v1.layers.Dense instead.\n",
      "\n",
      "W0711 13:13:31.250258 140484842403584 deprecation_wrapper.py:119] From /opt/conda/envs/python36_tf/lib/python3.6/site-packages/tensorflow/python/autograph/converters/directives.py:117: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "W0711 13:13:31.697020 140484842403584 deprecation_wrapper.py:119] From /home/jovyan/work/efficientnet_model.py:76: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n",
      "\n",
      "W0711 13:13:33.256690 140484842403584 deprecation_wrapper.py:119] From /opt/conda/envs/python36_tf/lib/python3.6/site-packages/tensorflow/python/autograph/converters/directives.py:117: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0711 13:13:33.365392 140484842403584 deprecation.py:323] From /opt/conda/envs/python36_tf/lib/python3.6/site-packages/tensorflow/python/autograph/impl/api.py:255: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n"
     ]
    }
   ],
   "source": [
    "blocks_args, global_params = efficientnet_builder.get_model_params(model_name, None)\n",
    "input = tf.keras.Input(shape=(224,224,3))\n",
    "basemodel = efficientnet_model.Model(blocks_args, global_params)\n",
    "with tf.variable_scope(model_name):\n",
    "    features = basemodel(input, training=True, features_only=True)\n",
    "    tf.train.init_from_checkpoint('./efficientnet-b0/model.ckpt', {'efficientnet-b0/':'efficientnet-b0/'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = tf.keras.Model(inputs=input,outputs=features)\n",
    "base_model.trainable = False\n",
    "model = tf.keras.Sequential([\n",
    "    base_model,\n",
    "    tf.keras.layers.GlobalAveragePooling2D(),\n",
    "    tf.keras.layers.Dense(1024,activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0711 13:13:41.273414 140484842403584 deprecation.py:323] From /opt/conda/envs/python36_tf/lib/python3.6/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "base_learning_rate = 0.0001\n",
    "model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=base_learning_rate),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n"
     ]
    }
   ],
   "source": [
    "initial_epochs = 10\n",
    "steps_per_epoch = round(len(tra_labels))//BATCH_SIZE\n",
    "validation_steps = round(len(val_labels))//BATCH_SIZE\n",
    "print(steps_per_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "500/500 [==============================] - 637s 1s/step - loss: 0.2118 - acc: 0.9094 - val_loss: 0.1232 - val_acc: 0.9542\n",
      "Epoch 2/10\n",
      "500/500 [==============================] - 606s 1s/step - loss: 0.1368 - acc: 0.9427 - val_loss: 0.1074 - val_acc: 0.9563\n",
      "Epoch 3/10\n",
      "500/500 [==============================] - 610s 1s/step - loss: 0.1234 - acc: 0.9509 - val_loss: 0.1092 - val_acc: 0.9553\n",
      "Epoch 4/10\n",
      "500/500 [==============================] - 610s 1s/step - loss: 0.1166 - acc: 0.9531 - val_loss: 0.0925 - val_acc: 0.9622\n",
      "Epoch 5/10\n",
      "500/500 [==============================] - 611s 1s/step - loss: 0.1110 - acc: 0.9554 - val_loss: 0.0963 - val_acc: 0.9617\n",
      "Epoch 6/10\n",
      "500/500 [==============================] - 610s 1s/step - loss: 0.0999 - acc: 0.9606 - val_loss: 0.0807 - val_acc: 0.9710\n",
      "Epoch 7/10\n",
      "500/500 [==============================] - 610s 1s/step - loss: 0.1010 - acc: 0.9592 - val_loss: 0.0709 - val_acc: 0.9703\n",
      "Epoch 8/10\n",
      "500/500 [==============================] - 610s 1s/step - loss: 0.0905 - acc: 0.9633 - val_loss: 0.0687 - val_acc: 0.9743\n",
      "Epoch 9/10\n",
      "500/500 [==============================] - 610s 1s/step - loss: 0.0899 - acc: 0.9646 - val_loss: 0.0764 - val_acc: 0.9707\n",
      "Epoch 10/10\n",
      "500/500 [==============================] - 609s 1s/step - loss: 0.0906 - acc: 0.9632 - val_loss: 0.0644 - val_acc: 0.9730\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_batches,\n",
    "                    epochs=initial_epochs,\n",
    "                    steps_per_epoch = steps_per_epoch,\n",
    "                    validation_data = val_batches,\n",
    "                    validation_steps = validation_steps )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT = 'output'\n",
    "\n",
    "if not os.path.exists(OUTPUT):\n",
    "    os.mkdir(OUTPUT)\n",
    "\n",
    "model.save_weights(os.path.join(OUTPUT, 'b0.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = round(len(test_labels))//BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "156/156 [==============================] - 160s 1s/step - loss: 0.0741 - acc: 0.9726\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.07409767107142565, 0.9725561]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_batches,steps=steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
