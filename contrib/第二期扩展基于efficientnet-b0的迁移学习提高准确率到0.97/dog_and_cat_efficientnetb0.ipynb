{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.14.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import tensorflow as tf\n",
    "#tf.enable_eager_execution()\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = './data/'\n",
    "model_name = model_name = 'efficientnet-b0'\n",
    "ckpt_dir = './efficientnet-b0/'\n",
    "export_ckpt_dir = None\n",
    "BATCH_SIZE = 32\n",
    "#MEAN_RGB = [0.485 * 255, 0.456 * 255, 0.406 * 255]\n",
    "#STDDEV_RGB = [0.229 * 255, 0.224 * 255, 0.225 * 255]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_image_paths = [DATA_DIR+i for i in os.listdir(DATA_DIR)]\n",
    "random.shuffle(all_image_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_image_labels=[]\n",
    "for i in all_image_paths:\n",
    "    if 'dog' in i:\n",
    "        all_image_labels.append(1)\n",
    "    else:\n",
    "        all_image_labels.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image):\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.resize(image, [224, 224])\n",
    "    #image -= tf.constant(MEAN_RGB, shape=[1, 1, 3], dtype=image.dtype)\n",
    "    #image /= tf.constant(STDDEV_RGB, shape=[1, 1, 3], dtype=image.dtype)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_image(path):\n",
    "    image = tf.io.read_file(path)\n",
    "    return preprocess_image(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_paths, test_paths, train_labels, test_labels = train_test_split(all_image_paths, all_image_labels, test_size=0.2, random_state=10)\n",
    "tra_paths,val_paths,tra_labels,val_labels = train_test_split(train_paths,train_labels,test_size=0.2,random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataset(images,labels):\n",
    "    ds = tf.data.Dataset.from_tensor_slices((tra_paths, tra_labels))\n",
    "    # The tuples are unpacked into the positional arguments of the mapped function\n",
    "    def load_and_preprocess_from_path_label(path, label):\n",
    "        return load_and_preprocess_image(path), label\n",
    "    image_label_ds = ds.map(load_and_preprocess_from_path_label)\n",
    "    ds = image_label_ds.apply(tf.data.experimental.shuffle_and_repeat(buffer_size=len(labels)))\n",
    "    ds = ds.batch(BATCH_SIZE).prefetch(buffer_size=AUTOTUNE)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0711 19:28:16.131233 10612 deprecation.py:323] From <ipython-input-9-07c1cf0db198>:7: shuffle_and_repeat (from tensorflow.python.data.experimental.ops.shuffle_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.shuffle(buffer_size, seed)` followed by `tf.data.Dataset.repeat(count)`. Static tf.data optimizations will take care of using the fused implementation.\n"
     ]
    }
   ],
   "source": [
    "train_batches = build_dataset(tra_paths,tra_labels)\n",
    "test_batches = build_dataset(test_paths,test_labels)\n",
    "val_batches = build_dataset(val_paths,val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#image_batch, label_batch = next(iter(ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0711 19:28:19.214233 10612 deprecation_wrapper.py:119] From F:\\jupyter\\efficientnet\\utils.py:86: The name tf.layers.BatchNormalization is deprecated. Please use tf.compat.v1.layers.BatchNormalization instead.\n",
      "\n",
      "W0711 19:28:19.217235 10612 deprecation_wrapper.py:119] From F:\\jupyter\\efficientnet\\utils.py:200: The name tf.layers.Layer is deprecated. Please use tf.compat.v1.layers.Layer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import efficientnet_model\n",
    "import efficientnet_builder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0711 19:28:19.249234 10612 deprecation_wrapper.py:119] From F:\\jupyter\\efficientnet\\efficientnet_builder.py:157: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
      "\n",
      "W0711 19:28:19.261233 10612 deprecation.py:506] From c:\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0711 19:28:19.264234 10612 deprecation_wrapper.py:119] From F:\\jupyter\\efficientnet\\efficientnet_model.py:201: The name tf.layers.Conv2D is deprecated. Please use tf.compat.v1.layers.Conv2D instead.\n",
      "\n",
      "W0711 19:28:19.309233 10612 deprecation_wrapper.py:119] From F:\\jupyter\\efficientnet\\efficientnet_model.py:372: The name tf.layers.Dense is deprecated. Please use tf.compat.v1.layers.Dense instead.\n",
      "\n",
      "W0711 19:28:19.520233 10612 deprecation_wrapper.py:119] From c:\\python36\\lib\\site-packages\\tensorflow\\python\\autograph\\converters\\directives.py:117: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "W0711 19:28:20.303233 10612 deprecation_wrapper.py:119] From F:\\jupyter\\efficientnet\\efficientnet_model.py:76: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n",
      "\n",
      "W0711 19:28:22.434234 10612 deprecation_wrapper.py:119] From c:\\python36\\lib\\site-packages\\tensorflow\\python\\autograph\\converters\\directives.py:117: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0711 19:28:22.596234 10612 deprecation.py:323] From c:\\python36\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:255: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n"
     ]
    }
   ],
   "source": [
    "blocks_args, global_params = efficientnet_builder.get_model_params(model_name, None)\n",
    "input = tf.keras.Input(shape=(224,224,3))\n",
    "basemodel = efficientnet_model.Model(blocks_args, global_params)\n",
    "with tf.variable_scope(model_name):\n",
    "    features = basemodel(input, training=True, features_only=True)\n",
    "    tf.train.init_from_checkpoint('./efficientnet-b0/model.ckpt', {'efficientnet-b0/':'efficientnet-b0/'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = tf.keras.Model(inputs=input,outputs=features)\n",
    "base_model.trainable = False\n",
    "model = tf.keras.Sequential([\n",
    "    base_model,\n",
    "    tf.keras.layers.GlobalAveragePooling2D(),\n",
    "    tf.keras.layers.Dense(1024,activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0711 19:28:28.979298 10612 deprecation.py:323] From c:\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "base_learning_rate = 0.0001\n",
    "model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=base_learning_rate),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n"
     ]
    }
   ],
   "source": [
    "initial_epochs = 10\n",
    "steps_per_epoch = round(len(tra_labels))//BATCH_SIZE\n",
    "validation_steps = round(len(val_labels))//BATCH_SIZE\n",
    "print(steps_per_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "500/500 [==============================] - 439s 878ms/step - loss: 0.2103 - acc: 0.9108 - val_loss: 0.1265 - val_acc: 0.9515\n",
      "Epoch 2/10\n",
      "500/500 [==============================] - 244s 489ms/step - loss: 0.1292 - acc: 0.9467 - val_loss: 0.1036 - val_acc: 0.9580\n",
      "Epoch 3/10\n",
      "500/500 [==============================] - 244s 489ms/step - loss: 0.1235 - acc: 0.9513 - val_loss: 0.1022 - val_acc: 0.9595\n",
      "Epoch 4/10\n",
      "500/500 [==============================] - 247s 493ms/step - loss: 0.1095 - acc: 0.9553 - val_loss: 0.0941 - val_acc: 0.9603\n",
      "Epoch 5/10\n",
      "500/500 [==============================] - 246s 492ms/step - loss: 0.1112 - acc: 0.9555 - val_loss: 0.0923 - val_acc: 0.9668\n",
      "Epoch 6/10\n",
      "500/500 [==============================] - 288s 577ms/step - loss: 0.1043 - acc: 0.9578 - val_loss: 0.0833 - val_acc: 0.9678\n",
      "Epoch 7/10\n",
      "500/500 [==============================] - 247s 494ms/step - loss: 0.0960 - acc: 0.9620 - val_loss: 0.1013 - val_acc: 0.9615\n",
      "Epoch 8/10\n",
      "500/500 [==============================] - 246s 491ms/step - loss: 0.0948 - acc: 0.9619 - val_loss: 0.0782 - val_acc: 0.9712\n",
      "Epoch 9/10\n",
      "500/500 [==============================] - 247s 494ms/step - loss: 0.0870 - acc: 0.9654 - val_loss: 0.0732 - val_acc: 0.9740\n",
      "Epoch 10/10\n",
      "500/500 [==============================] - 253s 507ms/step - loss: 0.0864 - acc: 0.9661 - val_loss: 0.0768 - val_acc: 0.9720\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_batches,\n",
    "                    epochs=initial_epochs,\n",
    "                    steps_per_epoch = steps_per_epoch,\n",
    "                    validation_data = val_batches,\n",
    "                    validation_steps = validation_steps )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT = 'output'\n",
    "\n",
    "if not os.path.exists(OUTPUT):\n",
    "    os.mkdir(OUTPUT)\n",
    "\n",
    "model.save_weights(os.path.join(OUTPUT, 'b0.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = round(len(test_labels))//BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "156/156 [==============================] - 120s 768ms/step - loss: 0.0665 - acc: 0.9750\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0664522725945482, 0.9749599]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_batches,steps=steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
