
# 华为云垃圾分类大赛模型调优心得分享
赛事链接如下[https://developer.huaweicloud.com/competition/competitions/1000007620/introduction]
## 探索历程
### 1、参加比赛背景及时间:
   本次华为组织的垃圾分类比赛时间在7月份已经公布，但是由于本人学习AI时间不长，最近3个月才紧跟华为云modelArts实战营进行学习，很多理论和原理不是很清楚，因此一直在忙于学习高等数学、概率论及CNN相关知识及原理，没及时关注本次垃圾分类大赛，直到8月28日才通过实战营同学口中得知本次垃圾分类大赛，因为各种原因和想法，最后才在9月2号开始报名垃圾分类比赛及下载代码、调优模型，直到9月10日最后一次提交，真正训练调优时间大概为4-5天时间，集中调优为周末2天，一个人调优从最初Baseline代码中的最初模型69%精度提高到最后9月10号调整到89.1%左右，排名131，虽然对自己的成绩还算满意，但一直觉得不知道该如何去写这个心得分享，因此一直没动手写，今天突然看到决赛亚军的分享心得，觉得有必要自己对本次调优过程也写下自己的分享。
### 2、Baseline从头开始
首先，由于时间紧迫，报名后加紧学些比赛规则、流程，然后从官方下载代码，数据集，大概看了下数据集为数量，并将数据集按9：1分成训练集和测试集，并按照官方提供的基本代码跑了一次（基本参数：ResNet50,batch_size=32,learning_rate=1e-4,epochs=10），在训练中，数据集和验证集的进度都非常高，达到98%以上，但最后对测试集进行验证模型好坏，得到进度缺只有69%左右，思考后觉得是不是数据集太少，模型复杂，导致容易出现过拟合问题，然后将模型采用熟悉的VGG16并采用Dropout防止过拟合，最后训练进度提升到73%，如下图：
<img src="./imgs/VGG-1-0.jpg">
<img  src="./imgs/vgg-1-1.jpg"><br>
### 2. 如何在现有数据集基础上提高模型精度
#### 2.1 调整参数
   在初步采用ResNet50和VGG16模型做了对比后，发现VGG16模型能达到73%的精度，比ResNet50模型精度有提高，于是初步采用了该模型做参数调优，基本围绕：
   Dropout(0.3)、batch_size、learning_rate、epochs几个参数进行调优。
#### 2.2 数据增广
   由于本次数据集只有1.9W张图，除掉10%的测试集和10%的验证集，训练集样本并不多，因此考虑对数据进行增广，但由于对图像处理技术不熟悉，只知道通过数据增广可以丰富特征的表达能力，因此采用modelArts实战营前期的数据增广部分对数据做随机剪切和变换，测试，发现数据提升不是很明显，后面又通过对训练数据的一张图片采用数据增广方法提升到7-8张，从而将训练数据提升到10-15W左右，再次进行训练能将模型提升到79.9%，如下图：
   <img src="./imgs/vgg-2-0.png">
#### 2.2 采用自适应学习率变化
   在模型进度达到79.9%后调整各项参数，很难让进度提升，后面在代码中增加自适应学习率方式，如下<br>
   lr = ReduceLROnPlateau(monitor="val_acc", factor=0.1, patience=2, verbose=1, mode="auto", min_lr=0.001)<br>
   Optimizer=adam(lr=FLAGS.learning_rate,beta_1=0.9,beta_2=0.999,decay=1e-6,clipnorm=0.0001)<br>
   最后发现可以提升该模型到81.5%，如图：
    <img src="./imgs/vgg-3-0.png">
#### 2.3 调整模型
   本次调优在相同参数下，更换模型由：ResNet50、VGG16、VGG19、
<br>
#### 2.2 模型架构更改
上述的做法提高的0.74后始终无法提升，考虑换个模型试试。参考过去的图像分类SOTA，发现keras提供了大量优秀的模型如NASNet，Inception，Xception等等。于是乎改模型架构的想法自然而然的诞生了。尝试了多种模型，但是奇怪的是在验证集合上的准确率始终停留在0.02~0.04基本处于瞎猜的水准。开始认为是图像处理的问题，对图像进行了```scale=1/255```，然而尽管验证准确率提高在测试准确率仍然停留在上述水平，百思不得其解最后上述思路，只得告吹。此番尝试，发现VGG，ResNet，MobileNet的模型可以尝试，但进一步尝试发现MobileNet，VGG的效果实际上还不如ResNet，最后只能继续基于ResNet进行考虑。
#### 2.3 ResNet更深的模型
既然其他模型不行，ResNet模型可以，那么更深的ResNet是不是可以获得更好的结果呢？出于这个考虑，立时考虑将ResNet50改为ResNet152。通过keras官方文档查阅知道keras.applications里由ResNet152。于是乎，马上动手改模型，将```from models.resnet50 import ResNet50```改为了```from keras.applications import ResNet152```并将模型改为了ResNet152。<br>
奇怪的事情又发生了，本地训练没有问题但是传上OBS创建训练作业，报错显示不存在模块ResNet152。无奈只好继续度娘，最后发现是ModelArts上keras-applications和keras版本低于官方文档的版本。好吧，那训练作业则么升级库？又不能像开发环境里直接```!pip install xxx ```。此处参考了ModelArt的官方文档,链接如下。[https://support.huaweicloud.com/modelarts_faq/modelarts_05_0063.html]
通过官方文档发现，需要在模型文件下引入pip-requirements.txt,进行依赖的安装升级，这里引入keras==2.2.5，keras-applications==1.0.8。然后ResNet152模型就可以上线了。<br>
此处实践会发现问题二，就是模型的预训练参数文件无法下载读取。通过查询，知道是训练作业过程无法连接外部网络，因此没法从Github上拉权重数据下来。因此只能对文件再次魔改一番，引入pretrained相关参数和在OBS和云之间的文件交互，从而读取预先下载好的传到OBS上的权重。通过这样一波改造，再训练基本上可以到0.8左右的准确率。那么问题是是否还能够提高呢？
#### 2.4 预训练上的思考
原始的预训练采用的思路是冻结了特征提取，并对最后加的两层Dense layer分类器进行训练，实际上并没有对特征提取进行调节。基于这个思路萌发了改造原始的代码训练最后5层的特征抽取和分类器训练，实际效果上可以发现有所提高，但是提高的不大，大概有1-2个点的提升。那么能否打开整个模型进行训练呢？思路上，感觉是可以得。但是目前的数据只有1.5W左右，训练整个模型数据量偏小，同时观察存在类别不均衡的情况，于是乎再进一步魔改做个数据增强，平衡一下类别，通过ImageDataGenerator将数据量增强到了70000多张图片，同时也缓解了类别不均衡问题。
于是乎在上述数据上再次训练，这次由于是采用全部打开的结构，训练时间非常长，所以架构上采用了ResNet50进行训练，差不多用了2个小时多在4*P100上训练（等价于8个小时在一个P100上训练），然后可喜的是模型获得了极大的提高准确率达到了0.86以上。
## 问题总结
目前的尝试中主要遇到了三个问题<br>
- 1. 改模型后准确率不正确，好吧这个问题最后还是没解决。
- 2. 引入keras.applications发现版本低的问题，最终通过引入pip-requirements.txt,进行依赖的安装升级。
- 3. 在最后的大模型上，选择了4*P100训练，但是发现部署不上，最后选择了单个P100训练
## 代码部分
本文将代码放在了同一文件夹下，放置的代码为ResNet50全开训练代码。
